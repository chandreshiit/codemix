{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SelfNet_mean_+_gelu_Youtube_Comments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YagaAp_xTg6W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSSRsC1fNADr"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muafgoq3zdah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd656d64-7473-458b-a6ed-4d04a16d7ab9"
      },
      "source": [
        "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8JsmnOWiV3w",
        "outputId": "3088615e-3bc4-49f1-f390-3529c8e7258d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive  #This is to make a short form for the mydrive location "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "ln: failed to create symbolic link '/mydrive/My Drive': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pPvkKXqib4A",
        "outputId": "13770aaf-6e6f-4c04-9733-612183fef4e6"
      },
      "source": [
        "!mkdir YoutubeCommentsDataset\n",
        "!unzip /mydrive/Code-Mix-Datasets/YoutubeCommentsDataset.zip -d YoutubeCommentsDataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘YoutubeCommentsDataset’: File exists\n",
            "Archive:  /mydrive/Code-Mix-Datasets/YoutubeCommentsDataset.zip\n",
            "replace YoutubeCommentsDataset/Information Regarding Data.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: YoutubeCommentsDataset/Information Regarding Data.txt  \n",
            "  inflating: YoutubeCommentsDataset/Youtube_Comments_Data.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4B0ARAXTkLp"
      },
      "source": [
        "### Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzzoO4vmNW1V"
      },
      "source": [
        "df_embedding = pd.read_csv('/mydrive/Code-Mix-Datasets/Embeddings/hing_emb', sep=\" \", quoting=3, header=None, index_col=0,skiprows=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2Wnirn_1ERuU",
        "outputId": "94f9f804-6f56-40c5-b8cb-6c083d841b70"
      },
      "source": [
        "df_embedding.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nahi</th>\n",
              "      <td>-0.079912</td>\n",
              "      <td>0.522077</td>\n",
              "      <td>0.009111</td>\n",
              "      <td>-0.103475</td>\n",
              "      <td>-0.042439</td>\n",
              "      <td>0.229031</td>\n",
              "      <td>0.360524</td>\n",
              "      <td>0.047913</td>\n",
              "      <td>0.129397</td>\n",
              "      <td>0.184819</td>\n",
              "      <td>0.037808</td>\n",
              "      <td>-0.516295</td>\n",
              "      <td>0.218961</td>\n",
              "      <td>-0.164668</td>\n",
              "      <td>0.180701</td>\n",
              "      <td>-0.386640</td>\n",
              "      <td>-0.068663</td>\n",
              "      <td>0.016217</td>\n",
              "      <td>0.045931</td>\n",
              "      <td>0.186454</td>\n",
              "      <td>-0.083010</td>\n",
              "      <td>-0.081126</td>\n",
              "      <td>0.172391</td>\n",
              "      <td>0.063896</td>\n",
              "      <td>0.047010</td>\n",
              "      <td>-0.069440</td>\n",
              "      <td>0.074594</td>\n",
              "      <td>-0.237348</td>\n",
              "      <td>0.044247</td>\n",
              "      <td>0.060424</td>\n",
              "      <td>-0.156759</td>\n",
              "      <td>-0.452560</td>\n",
              "      <td>0.343487</td>\n",
              "      <td>-0.115351</td>\n",
              "      <td>0.180884</td>\n",
              "      <td>-0.125824</td>\n",
              "      <td>0.189236</td>\n",
              "      <td>-0.144955</td>\n",
              "      <td>-0.339609</td>\n",
              "      <td>0.361464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149655</td>\n",
              "      <td>0.218875</td>\n",
              "      <td>0.241330</td>\n",
              "      <td>0.223399</td>\n",
              "      <td>-0.238831</td>\n",
              "      <td>-0.255176</td>\n",
              "      <td>-0.217318</td>\n",
              "      <td>0.172820</td>\n",
              "      <td>-0.086227</td>\n",
              "      <td>-0.201589</td>\n",
              "      <td>0.186472</td>\n",
              "      <td>0.172828</td>\n",
              "      <td>0.274141</td>\n",
              "      <td>-0.322574</td>\n",
              "      <td>0.118850</td>\n",
              "      <td>-0.039497</td>\n",
              "      <td>0.558407</td>\n",
              "      <td>-0.062534</td>\n",
              "      <td>0.144667</td>\n",
              "      <td>-0.311163</td>\n",
              "      <td>-0.056226</td>\n",
              "      <td>-0.450764</td>\n",
              "      <td>-0.219975</td>\n",
              "      <td>-0.270082</td>\n",
              "      <td>0.245673</td>\n",
              "      <td>0.245098</td>\n",
              "      <td>-0.251164</td>\n",
              "      <td>-0.048588</td>\n",
              "      <td>-0.308297</td>\n",
              "      <td>-0.325541</td>\n",
              "      <td>0.049488</td>\n",
              "      <td>-0.291750</td>\n",
              "      <td>0.188353</td>\n",
              "      <td>-0.099099</td>\n",
              "      <td>0.271938</td>\n",
              "      <td>0.311072</td>\n",
              "      <td>-0.446256</td>\n",
              "      <td>-0.093532</td>\n",
              "      <td>0.118786</td>\n",
              "      <td>-0.221102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.268486</td>\n",
              "      <td>0.454443</td>\n",
              "      <td>-0.211620</td>\n",
              "      <td>-0.029896</td>\n",
              "      <td>-0.123828</td>\n",
              "      <td>0.119760</td>\n",
              "      <td>0.146776</td>\n",
              "      <td>0.152356</td>\n",
              "      <td>0.136670</td>\n",
              "      <td>-0.086144</td>\n",
              "      <td>-0.050878</td>\n",
              "      <td>0.013576</td>\n",
              "      <td>0.040101</td>\n",
              "      <td>-0.305341</td>\n",
              "      <td>0.180583</td>\n",
              "      <td>-0.021216</td>\n",
              "      <td>-0.220805</td>\n",
              "      <td>-0.273808</td>\n",
              "      <td>-0.055823</td>\n",
              "      <td>0.103470</td>\n",
              "      <td>-0.067804</td>\n",
              "      <td>-0.220657</td>\n",
              "      <td>0.583009</td>\n",
              "      <td>0.041388</td>\n",
              "      <td>0.046626</td>\n",
              "      <td>-0.076103</td>\n",
              "      <td>-0.099535</td>\n",
              "      <td>0.033646</td>\n",
              "      <td>-0.273642</td>\n",
              "      <td>0.041777</td>\n",
              "      <td>0.049301</td>\n",
              "      <td>0.017838</td>\n",
              "      <td>0.120956</td>\n",
              "      <td>-0.157904</td>\n",
              "      <td>0.218910</td>\n",
              "      <td>-0.127773</td>\n",
              "      <td>-0.149346</td>\n",
              "      <td>-0.056826</td>\n",
              "      <td>-0.404863</td>\n",
              "      <td>0.480747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103053</td>\n",
              "      <td>0.046495</td>\n",
              "      <td>0.440512</td>\n",
              "      <td>-0.009003</td>\n",
              "      <td>-0.612618</td>\n",
              "      <td>-0.262637</td>\n",
              "      <td>0.072368</td>\n",
              "      <td>0.173662</td>\n",
              "      <td>0.149637</td>\n",
              "      <td>-0.022141</td>\n",
              "      <td>0.092603</td>\n",
              "      <td>-0.187714</td>\n",
              "      <td>0.202985</td>\n",
              "      <td>-0.423206</td>\n",
              "      <td>0.196088</td>\n",
              "      <td>-0.210534</td>\n",
              "      <td>0.215506</td>\n",
              "      <td>-0.164961</td>\n",
              "      <td>0.310179</td>\n",
              "      <td>0.100638</td>\n",
              "      <td>0.222475</td>\n",
              "      <td>-0.188912</td>\n",
              "      <td>-0.183798</td>\n",
              "      <td>-0.131548</td>\n",
              "      <td>0.143710</td>\n",
              "      <td>0.026334</td>\n",
              "      <td>-0.238585</td>\n",
              "      <td>0.075989</td>\n",
              "      <td>-0.113403</td>\n",
              "      <td>-0.373096</td>\n",
              "      <td>0.256750</td>\n",
              "      <td>0.170485</td>\n",
              "      <td>-0.081619</td>\n",
              "      <td>-0.110159</td>\n",
              "      <td>-0.012980</td>\n",
              "      <td>0.211806</td>\n",
              "      <td>-0.197437</td>\n",
              "      <td>0.094797</td>\n",
              "      <td>-0.070250</td>\n",
              "      <td>-0.186570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ki</th>\n",
              "      <td>-0.342798</td>\n",
              "      <td>0.568509</td>\n",
              "      <td>0.049298</td>\n",
              "      <td>-0.111945</td>\n",
              "      <td>-0.312412</td>\n",
              "      <td>0.490620</td>\n",
              "      <td>0.442846</td>\n",
              "      <td>0.053863</td>\n",
              "      <td>0.177461</td>\n",
              "      <td>0.111002</td>\n",
              "      <td>0.312172</td>\n",
              "      <td>-0.602531</td>\n",
              "      <td>0.264498</td>\n",
              "      <td>-0.201628</td>\n",
              "      <td>0.376125</td>\n",
              "      <td>-0.395881</td>\n",
              "      <td>0.124789</td>\n",
              "      <td>-0.473777</td>\n",
              "      <td>0.126820</td>\n",
              "      <td>0.086264</td>\n",
              "      <td>0.170230</td>\n",
              "      <td>0.236199</td>\n",
              "      <td>0.245333</td>\n",
              "      <td>0.342971</td>\n",
              "      <td>-0.014456</td>\n",
              "      <td>-0.012857</td>\n",
              "      <td>0.217287</td>\n",
              "      <td>-0.167022</td>\n",
              "      <td>-0.175880</td>\n",
              "      <td>-0.169058</td>\n",
              "      <td>-0.369584</td>\n",
              "      <td>-0.350195</td>\n",
              "      <td>0.237084</td>\n",
              "      <td>0.131265</td>\n",
              "      <td>-0.046302</td>\n",
              "      <td>-0.109374</td>\n",
              "      <td>-0.025367</td>\n",
              "      <td>0.038076</td>\n",
              "      <td>-0.132978</td>\n",
              "      <td>0.404412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.315271</td>\n",
              "      <td>0.054077</td>\n",
              "      <td>0.225164</td>\n",
              "      <td>0.142596</td>\n",
              "      <td>-0.407171</td>\n",
              "      <td>-0.082441</td>\n",
              "      <td>-0.147046</td>\n",
              "      <td>0.083077</td>\n",
              "      <td>0.065228</td>\n",
              "      <td>0.372545</td>\n",
              "      <td>0.237747</td>\n",
              "      <td>0.228064</td>\n",
              "      <td>0.267732</td>\n",
              "      <td>-0.206860</td>\n",
              "      <td>0.339351</td>\n",
              "      <td>0.162408</td>\n",
              "      <td>0.475990</td>\n",
              "      <td>-0.131715</td>\n",
              "      <td>0.222665</td>\n",
              "      <td>-0.334802</td>\n",
              "      <td>-0.086397</td>\n",
              "      <td>-0.206919</td>\n",
              "      <td>-0.189970</td>\n",
              "      <td>-0.229659</td>\n",
              "      <td>0.076044</td>\n",
              "      <td>-0.197885</td>\n",
              "      <td>0.092336</td>\n",
              "      <td>0.224985</td>\n",
              "      <td>-0.054457</td>\n",
              "      <td>-0.033281</td>\n",
              "      <td>0.491238</td>\n",
              "      <td>-0.074531</td>\n",
              "      <td>0.165319</td>\n",
              "      <td>-0.015633</td>\n",
              "      <td>0.151389</td>\n",
              "      <td>0.332968</td>\n",
              "      <td>-0.311262</td>\n",
              "      <td>0.057184</td>\n",
              "      <td>-0.281329</td>\n",
              "      <td>-0.346765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ke</th>\n",
              "      <td>-0.299528</td>\n",
              "      <td>0.510413</td>\n",
              "      <td>-0.033908</td>\n",
              "      <td>-0.064933</td>\n",
              "      <td>-0.439092</td>\n",
              "      <td>0.359395</td>\n",
              "      <td>0.342511</td>\n",
              "      <td>-0.102557</td>\n",
              "      <td>0.354761</td>\n",
              "      <td>0.632507</td>\n",
              "      <td>0.167711</td>\n",
              "      <td>-0.358377</td>\n",
              "      <td>0.111304</td>\n",
              "      <td>0.085862</td>\n",
              "      <td>0.180126</td>\n",
              "      <td>-0.066881</td>\n",
              "      <td>0.099755</td>\n",
              "      <td>-0.068138</td>\n",
              "      <td>0.302462</td>\n",
              "      <td>-0.110525</td>\n",
              "      <td>0.085888</td>\n",
              "      <td>-0.144101</td>\n",
              "      <td>0.242838</td>\n",
              "      <td>-0.121287</td>\n",
              "      <td>0.384848</td>\n",
              "      <td>-0.145164</td>\n",
              "      <td>-0.028000</td>\n",
              "      <td>-0.206916</td>\n",
              "      <td>0.156869</td>\n",
              "      <td>-0.467113</td>\n",
              "      <td>0.024789</td>\n",
              "      <td>-0.176063</td>\n",
              "      <td>-0.090807</td>\n",
              "      <td>0.113101</td>\n",
              "      <td>-0.039015</td>\n",
              "      <td>-0.156265</td>\n",
              "      <td>0.282400</td>\n",
              "      <td>-0.011621</td>\n",
              "      <td>-0.006955</td>\n",
              "      <td>0.495004</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084984</td>\n",
              "      <td>0.280584</td>\n",
              "      <td>0.178200</td>\n",
              "      <td>0.169110</td>\n",
              "      <td>-0.342354</td>\n",
              "      <td>-0.104760</td>\n",
              "      <td>-0.074415</td>\n",
              "      <td>0.462324</td>\n",
              "      <td>-0.157399</td>\n",
              "      <td>-0.167785</td>\n",
              "      <td>-0.185156</td>\n",
              "      <td>-0.161399</td>\n",
              "      <td>0.015410</td>\n",
              "      <td>-0.401743</td>\n",
              "      <td>0.125092</td>\n",
              "      <td>0.100341</td>\n",
              "      <td>0.459452</td>\n",
              "      <td>-0.061197</td>\n",
              "      <td>0.009943</td>\n",
              "      <td>-0.189876</td>\n",
              "      <td>0.103493</td>\n",
              "      <td>0.035745</td>\n",
              "      <td>0.167451</td>\n",
              "      <td>-0.301508</td>\n",
              "      <td>-0.042029</td>\n",
              "      <td>0.023666</td>\n",
              "      <td>-0.143649</td>\n",
              "      <td>0.070190</td>\n",
              "      <td>-0.000454</td>\n",
              "      <td>-0.118479</td>\n",
              "      <td>0.202599</td>\n",
              "      <td>-0.206487</td>\n",
              "      <td>0.178269</td>\n",
              "      <td>-0.108783</td>\n",
              "      <td>0.322591</td>\n",
              "      <td>0.347032</td>\n",
              "      <td>-0.558663</td>\n",
              "      <td>-0.018923</td>\n",
              "      <td>0.116121</td>\n",
              "      <td>-0.325165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>se</th>\n",
              "      <td>-0.435697</td>\n",
              "      <td>0.357603</td>\n",
              "      <td>-0.040995</td>\n",
              "      <td>0.107330</td>\n",
              "      <td>-0.313671</td>\n",
              "      <td>0.268082</td>\n",
              "      <td>0.246396</td>\n",
              "      <td>0.005616</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>0.249072</td>\n",
              "      <td>0.030711</td>\n",
              "      <td>-0.516266</td>\n",
              "      <td>0.153362</td>\n",
              "      <td>-0.085299</td>\n",
              "      <td>0.171405</td>\n",
              "      <td>-0.030755</td>\n",
              "      <td>-0.162353</td>\n",
              "      <td>-0.314957</td>\n",
              "      <td>0.067558</td>\n",
              "      <td>0.356368</td>\n",
              "      <td>0.173713</td>\n",
              "      <td>-0.225910</td>\n",
              "      <td>0.490172</td>\n",
              "      <td>0.066194</td>\n",
              "      <td>0.041909</td>\n",
              "      <td>-0.225645</td>\n",
              "      <td>0.067686</td>\n",
              "      <td>-0.216134</td>\n",
              "      <td>-0.176741</td>\n",
              "      <td>0.163501</td>\n",
              "      <td>0.008431</td>\n",
              "      <td>-0.266124</td>\n",
              "      <td>0.157955</td>\n",
              "      <td>-0.066839</td>\n",
              "      <td>0.118103</td>\n",
              "      <td>0.194242</td>\n",
              "      <td>0.204604</td>\n",
              "      <td>0.208945</td>\n",
              "      <td>-0.222251</td>\n",
              "      <td>0.397446</td>\n",
              "      <td>...</td>\n",
              "      <td>0.321824</td>\n",
              "      <td>0.252558</td>\n",
              "      <td>0.402438</td>\n",
              "      <td>0.194747</td>\n",
              "      <td>-0.520264</td>\n",
              "      <td>0.130659</td>\n",
              "      <td>-0.343827</td>\n",
              "      <td>0.375568</td>\n",
              "      <td>-0.124099</td>\n",
              "      <td>-0.089241</td>\n",
              "      <td>0.073819</td>\n",
              "      <td>-0.067210</td>\n",
              "      <td>-0.131197</td>\n",
              "      <td>-0.376184</td>\n",
              "      <td>0.359206</td>\n",
              "      <td>0.070664</td>\n",
              "      <td>0.396609</td>\n",
              "      <td>-0.182876</td>\n",
              "      <td>0.060587</td>\n",
              "      <td>-0.114624</td>\n",
              "      <td>-0.045065</td>\n",
              "      <td>-0.147356</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>-0.341763</td>\n",
              "      <td>-0.002624</td>\n",
              "      <td>0.114512</td>\n",
              "      <td>-0.412783</td>\n",
              "      <td>0.196286</td>\n",
              "      <td>-0.188970</td>\n",
              "      <td>0.156763</td>\n",
              "      <td>0.409665</td>\n",
              "      <td>-0.106801</td>\n",
              "      <td>-0.285788</td>\n",
              "      <td>0.028810</td>\n",
              "      <td>0.064475</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>-0.666445</td>\n",
              "      <td>-0.167434</td>\n",
              "      <td>-0.310887</td>\n",
              "      <td>-0.367422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           1         2         3    ...       98        99        100\n",
              "0                                   ...                              \n",
              "nahi -0.079912  0.522077  0.009111  ... -0.093532  0.118786 -0.221102\n",
              "to    0.268486  0.454443 -0.211620  ...  0.094797 -0.070250 -0.186570\n",
              "ki   -0.342798  0.568509  0.049298  ...  0.057184 -0.281329 -0.346765\n",
              "ke   -0.299528  0.510413 -0.033908  ... -0.018923  0.116121 -0.325165\n",
              "se   -0.435697  0.357603 -0.040995  ... -0.167434 -0.310887 -0.367422\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJaOLL02TmUy"
      },
      "source": [
        "### Create vocab dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456blVxHEqJK",
        "outputId": "1fabfa5e-e9db-40dc-ab0d-d166d43011d8"
      },
      "source": [
        "m = df_embedding.to_numpy()\n",
        "m.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKURV7-5NXfE",
        "outputId": "aa55221f-8b72-43cf-ead5-c93cc46fc391"
      },
      "source": [
        "embedding_matrix = df_embedding.to_numpy()\n",
        "\n",
        "vocab = []\n",
        "\n",
        "for word in list(df_embedding.index):\n",
        "  vocab.append(str(word))\n",
        "\n",
        "vocab_size , vocab_dim = embedding_matrix.shape\n",
        "vocab_size, vocab_dim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHZGs3aFF6b",
        "outputId": "a2d76acf-4109-40cb-f952-a38c12680201"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40599"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rju-5mvbVp6H"
      },
      "source": [
        "word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY77Ru_NFMMs",
        "outputId": "45e84371-3f06-494c-dfb6-4ec87e2edd77"
      },
      "source": [
        "len(word2idx) , len(idx2word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40598, 40599)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBRDCquFF62W",
        "outputId": "ce912395-b2d0-479c-d114-549f630f681d"
      },
      "source": [
        "import itertools\n",
        "dict(itertools.islice(word2idx.items(), 10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bhi': 9,\n",
              " 'ka': 7,\n",
              " 'ke': 3,\n",
              " 'ki': 2,\n",
              " 'ko': 5,\n",
              " 'me': 8,\n",
              " 'nahi': 0,\n",
              " 'se': 4,\n",
              " 'the': 6,\n",
              " 'to': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0HS8bPTqWq"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbzhx5a0m_Sr"
      },
      "source": [
        "def sub_one(x):\n",
        "\treturn x - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSukKoeeNvSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5d640e-fe25-4325-8fd9-cda5c59e06d6"
      },
      "source": [
        "df = pd.read_csv('/content/YoutubeCommentsDataset/Youtube_Comments_Data.csv')\n",
        "df= df.sample(frac = 1)\n",
        "\n",
        "df['Labels'] = df['Labels'].apply(sub_one)\n",
        "\n",
        "train_df = df[:6800]\n",
        "val_df = df[6800:8300]\n",
        "test_df = df[8300:]\n",
        "\n",
        "train_df.head()\n",
        "\n",
        "\n",
        "train_data =  train_df['commentText'].values\n",
        "train_labels = train_df['Labels'].values\n",
        "\n",
        "val_data =  val_df['commentText'].values\n",
        "val_labels = val_df['Labels'].values\n",
        "\n",
        "test_data =  test_df['commentText'].values\n",
        "test_labels = test_df['Labels'].values\n",
        "\n",
        "print(len(train_data), len(train_labels))\n",
        "print(len(val_data), len(val_labels))\n",
        "print(len(test_data), len(test_labels))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6800 6800\n",
            "1500 1500\n",
            "1500 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FMJNuKrDn-xb",
        "outputId": "0d136085-6d5e-44c5-c7ae-13f046263e35"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>commentText</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8083</th>\n",
              "      <td>Ugh4PSCj66Glk3gCoAEC</td>\n",
              "      <td>It is the tastiest samosa ever</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3553</th>\n",
              "      <td>Ugz97IPpb6wizkGTkUJ4AaABAg</td>\n",
              "      <td>Nice recipe di</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6741</th>\n",
              "      <td>UghzVKEiApWLmXgCoAEC</td>\n",
              "      <td>Nice</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4568</th>\n",
              "      <td>UgjRiq4pfN_yCngCoAEC</td>\n",
              "      <td>its vry easy thank you mam</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5837</th>\n",
              "      <td>UgxYFbPTEyY9HjqGHgJ4AaABAg</td>\n",
              "      <td>man it's really good but jese 1-2 minutes Me k...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id  ... Labels\n",
              "8083        Ugh4PSCj66Glk3gCoAEC  ...      1\n",
              "3553  Ugz97IPpb6wizkGTkUJ4AaABAg  ...      1\n",
              "6741        UghzVKEiApWLmXgCoAEC  ...      2\n",
              "4568        UgjRiq4pfN_yCngCoAEC  ...      4\n",
              "5837  UgxYFbPTEyY9HjqGHgJ4AaABAg  ...      5\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83AlL80DN1_5"
      },
      "source": [
        "\n",
        "# post = pd.read_csv(\"positive_add1and2.csv\",sep=',')\n",
        "# neg = pd.read_csv(\"negative_add_1and2.csv\",sep=',')\n",
        "\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "# for index, row in post.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(1)\n",
        "\n",
        "\n",
        "# for index, row in neg.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(0)\n",
        "  \n",
        "\n",
        "# len(data), len(labels)\n",
        "\n",
        "# data, labels  = shuffle(data, labels, random_state = 40)\n",
        "\n",
        "# data[0], labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5iYXAJbTwJ8"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgF5Hb8weYwB"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "\n",
        "def tokenized_tensor(data):\n",
        "\n",
        "  output_tokenized = []\n",
        "\n",
        "  for sentence in data:\n",
        "    output = []\n",
        "    tokenized = tokenizer(sentence)\n",
        "    \n",
        "    for word in tokenized:\n",
        "      if word in word2idx:\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "      else:\n",
        "        word2idx[word] = len(word2idx)\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "\n",
        "    output = torch.tensor(output)\n",
        "\n",
        "\n",
        "    output_tokenized.append(output)\n",
        "\n",
        "  return output_tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_pDpPLhiUPG"
      },
      "source": [
        "# tokenized_sequences = tokenized_tensor(data)\n",
        "\n",
        "train_tokenized_sequences = tokenized_tensor(train_data)\n",
        "\n",
        "test_tokenized_seuqences = tokenized_tensor(test_data)\n",
        "\n",
        "val_tokenized_seuquences = tokenized_tensor(val_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6WOxrifIFKQ",
        "outputId": "ef207cd4-55fc-456f-bc8e-adaadbe1cc96"
      },
      "source": [
        "print(train_tokenized_sequences[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1345, 4659,  276])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poFrSB5Opl1-",
        "outputId": "0bad193a-cf73-4f71-e6e9-509bfec95058"
      },
      "source": [
        "word2idx['<PAD>'] = len(word2idx)\n",
        "word2idx['<PAD>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44838"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9AZYccLbVof",
        "outputId": "bf73d6d9-113b-4880-9a85-a27c29d13ae9"
      },
      "source": [
        "len(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44839"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYstutbgrABv"
      },
      "source": [
        "## Create embedding matrix\n",
        "\n",
        "random_init = torch.nn.Parameter(torch.Tensor( (len(word2idx) - vocab_size), vocab_dim))\n",
        "torch.nn.init.kaiming_uniform_(random_init, a=math.sqrt(5))\n",
        "\n",
        "\n",
        "new_matrix = np.zeros( (len(word2idx), vocab_dim) )\n",
        "\n",
        "new_matrix[:vocab_size, :] = embedding_matrix\n",
        "\n",
        "embedding_matrix = new_matrix\n",
        "\n",
        "embedding_matrix[vocab_size:, :] = random_init.detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0mL0x6J3KV",
        "outputId": "32d4bf4d-7ec2-4085-fce3-6c7b82f0922a"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44839, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cp0nnNdrazK"
      },
      "source": [
        "# padded_sequences = pad_sequence(tokenized_sequences, batch_first= True, padding_value=107512)\n",
        "\n",
        "train_padded_sequences = pad_sequence(train_tokenized_sequences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "val_padded_sequences = pad_sequence(val_tokenized_seuquences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "test_padded_sequences = pad_sequence(test_tokenized_seuqences, batch_first= True, padding_value=word2idx['<PAD>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trl1D4QFII3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281787e8-4bbd-4b9c-dea0-6f937b0b3f9a"
      },
      "source": [
        "(train_padded_sequences[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1345,  4659,   276, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSE4xlb2O8Ju"
      },
      "source": [
        "### Dataset and Data loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISg-6szPOBr1"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
        "    \"\"\"\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.labels = labels\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        sequence = self.sequences[idx]\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        try:\n",
        "            sample[\"label\"] = label\n",
        "            sample[\"token\"] = sequence\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1LEy0ogII3g"
      },
      "source": [
        "train_dataset = Dataset(train_padded_sequences, train_labels)\n",
        "\n",
        "val_dataset = Dataset(val_padded_sequences, val_labels)\n",
        "\n",
        "test_dataset = Dataset(test_padded_sequences, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQVUtYvII3g"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC2nFBOTynbR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENWuqJHeII3h"
      },
      "source": [
        "## Hyper parameter\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "embed_dim = vocab_dim\n",
        "seq_len = 192\n",
        "hidden_size = 512\n",
        "num_layer = 3\n",
        "num_class = 7\n",
        "batch_size = 256\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 5\n",
        "CLIP = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2daJrk6PQb7"
      },
      "source": [
        "# # Create datasets\n",
        "# dataset = Dataset(padded_sequences, labels)\n",
        "\n",
        "# split = 0.85\n",
        "# train_size = int(split*len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSYO1yrqPSgn"
      },
      "source": [
        "\n",
        "## We call the dataloader class\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "## For testing\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "\n",
        "dataloaders = {'Train': train_loader, 'Val': val_loader}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ZYd39BII3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a10a91c-2116-4ada-e1f6-e3abc17ea147"
      },
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 5, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoA6yF7iomTV",
        "outputId": "418e1523-d735-4082-f963-16580e8ea844"
      },
      "source": [
        "max_len = -1\n",
        "for comment in val_dataset:\n",
        "  sentence = comment['token']\n",
        "  max_len = max(max_len,sentence.shape[0])\n",
        "\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0DXO4Q2II3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471b3762-68ba-4ac6-8f4c-2acd20a5b427"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': tensor(1),\n",
              " 'token': tensor([   58,    12,     6, 40598,  9834,   811, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838])}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXQNerMvjIb"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR0tnE2NxphD"
      },
      "source": [
        "class SelfMatchingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,  seq_length, embed_dim, **kwargs):\n",
        "\n",
        "      super(SelfMatchingLayer, self).__init__()\n",
        "\n",
        "      self.seq_length = seq_length\n",
        "      self.embed_dim  = embed_dim\n",
        "\n",
        "      self.P = torch.nn.Parameter(torch.Tensor(self.embed_dim, self.embed_dim))\n",
        "\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.P, a=math.sqrt(5))\n",
        "\n",
        "      \n",
        "    def forward(self, x):  \n",
        "      \n",
        "      # input shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "\n",
        "      #---------------------------------------------#\n",
        "      # calculate weight vector a = {e_i . P.Q . e_j}\n",
        "      #---------------------------------------------#\n",
        "\n",
        "      out = torch.matmul(x,  self.P)   #out shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "      out = torch.matmul(out, torch.transpose(x, 1, 2))   #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = F.gelu(out)         # apply non linear activation\n",
        "\n",
        "      #------------------------------------#\n",
        "      # take row wise mean and apply softmax\n",
        "      #------------------------------------#\n",
        "      out = torch.mean(out, 2)  #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = torch.softmax(out, 0)     #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = out.unsqueeze(1)          #out shape: [batch, 1, seq_len]\n",
        "\n",
        "      #-------------------------------------------#\n",
        "      # calculate weighted embedding of every word\n",
        "      #-------------------------------------------#\n",
        "      out = torch.matmul(out, x)\n",
        "\n",
        "      out = out.squeeze(1)\n",
        "\n",
        "      return out      #out shape: [batch, seq_len]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkC2PE1q3Fq",
        "outputId": "5188e8ce-3efa-4280-f761-511c46f26e2a"
      },
      "source": [
        "word2idx['<PAD>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44838"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFAeZSyXu9KJ"
      },
      "source": [
        "class SelfNet(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class):\n",
        "        super(SelfNet, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = word2idx['<PAD>'])\n",
        "        self.embedding.load_state_dict({'weight': torch.from_numpy(embedding_matrix)})\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        self.selfnet_layer = SelfMatchingLayer(seq_len, embed_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = num_layer, dropout = 0.3, bidirectional = True, batch_first = True )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2* hidden_size + embed_dim , hidden_size//4)\n",
        "        self.fc2 = nn.Linear(hidden_size//4, num_class)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        embedded = self.embedding(input)  #out shape = [batch, seq_len, embed_dim] \n",
        "\n",
        "        selfmatch_output = self.selfnet_layer(embedded)  #out shape = [batch, seq_len] \n",
        "\n",
        "        lstm_out, _ = self.lstm(embedded)     \n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]      #out shape = [batch, 2 * hidden_size]      \n",
        "\n",
        "        concat = torch.cat( (selfmatch_output, lstm_out), 1)     #out shape = [batch, 2 * hidden_size + seq_len ]      \n",
        "\n",
        "        linear_out = self.dropout(F.relu(self.fc1(concat)))     #out shape = [batch, hidden_size]      \n",
        "\n",
        "        final_out = self.fc2(linear_out)     #out shape = [batch, 2]      \n",
        "\n",
        "        return final_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msc1-1zlOtAh"
      },
      "source": [
        "\n",
        "### Test\n",
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\n",
        "# model = model.to(device)\n",
        "\n",
        "# for batch in train_loader:\n",
        "#   x = batch['token'].to(device)\n",
        "#   out = model(x)\n",
        "#   print(out.shape)\n",
        "#   break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XvE3WHII3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf727e6-066f-49bc-d07b-e32dfa27a9a0"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xjqPfmqx5Hj"
      },
      "source": [
        "### Optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifFhRpc2x4Fv"
      },
      "source": [
        "#optimizer\n",
        "optimizer = Adam(model.parameters(), lr = LEARNING_RATE, eps=1e-8)\n",
        "#Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ozLaUUx-eo"
      },
      "source": [
        "#to calculate accuracy\n",
        "\n",
        "def get_accuracy(preds, labels):\n",
        "  total_acc = 0.0\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    if labels[i] == preds[i]:\n",
        "      total_acc+=1.0\n",
        "  \n",
        "  return total_acc / len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D33SEPjzILZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP5of6JbII3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58296fc2-81e5-4394-eec6-d979870d53b0"
      },
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5, verbose = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o0-BUMKII3o"
      },
      "source": [
        "PATH = 'models/best_selfnet_mean+gelu_2.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZkPq1t6yBwx",
        "outputId": "4a678302-dc2f-421d-a886-c7448087ca26"
      },
      "source": [
        "best_valid_f1 = 0.0000\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "  \n",
        "\n",
        "    print('-'*50)\n",
        "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
        "\n",
        "    for phase in ['Train', 'Val']:\n",
        "\n",
        "        loss = 0.0   #epoch loss\n",
        "        accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        if phase == 'Train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        \n",
        "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
        "\n",
        "          for batch in tepoch:\n",
        "            labels = batch[\"label\"]\n",
        "            text = batch[\"token\"]\n",
        "\n",
        "            output = model(text)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            if phase == 'Train':\n",
        "\n",
        "                #zero gradients\n",
        "                optimizer.zero_grad() \n",
        "\n",
        "                # Backward pass  (calculates the gradients)\n",
        "                loss.backward()   \n",
        "\n",
        "                # gradient clipping\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
        "\n",
        "                optimizer.step()             # Updates the weights    \n",
        "\n",
        "            sleep(0.1)\n",
        "            _, preds = output.data.max(1)\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "            \n",
        "            batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "            \n",
        "            \n",
        "            loss += loss.item()\n",
        "            accuracy+= batch_acc\n",
        "\n",
        "              \n",
        "          epoch_loss = loss / (len(dataloaders[phase]))\n",
        "          epoch_acc = accuracy / (len(dataloaders[phase]))\n",
        "\n",
        "          print(phase + \":\")\n",
        "          \n",
        "          \n",
        "          #print(confusion_matrix(y_true, y_pred))\n",
        "          pre = precision_score(y_true, y_pred, average='weighted')\n",
        "          recall = recall_score(y_true, y_pred, average='weighted')\n",
        "          f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "          \n",
        "\n",
        "          print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))\n",
        "          # save best model\n",
        "          print()\n",
        "          \n",
        "            \n",
        "          if phase == 'Val':\n",
        "                \n",
        "                if f1 > best_valid_f1:\n",
        "                    best_valid_f1 = f1\n",
        "                    \n",
        "                    torch.save(model.state_dict(), PATH)\n",
        "                    print('Model Saved!')\n",
        "                    \n",
        "                scheduler.step(f1)\n",
        "                    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/26 [00:00<?, ?batch/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yJchRvUz2nf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsq5MiaHII3r"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L66ZUsoII3r"
      },
      "source": [
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EceKQVWTII3r"
      },
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1DB4Su5II3r"
      },
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X99rC-LvII3s"
      },
      "source": [
        "model.load_state_dict(torch.load('models/best_selfnet_mean+gelu.pt'))\n",
        "\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQwRQc_NII3s"
      },
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQs04_VAII3t"
      },
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Kth3CNII3t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMwq-cvgKn1w"
      },
      "source": [
        ""
      ]
    }
  ]
}