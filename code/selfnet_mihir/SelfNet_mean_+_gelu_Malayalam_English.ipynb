{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Malayalam English Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YagaAp_xTg6W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 2.7 MB/s \n",
            "\u001b[?25hCollecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (2.26.0)\n",
            "Requirement already satisfied: numpy in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (4.62.2)\n",
            "Requirement already satisfied: typing-extensions in /home/ckm/python3.7/lib/python3.7/site-packages (from torch==1.10.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (1.26.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (2021.5.30)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.1\n",
            "    Uninstalling torch-1.9.1:\n",
            "      Successfully uninstalled torch-1.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.1 requires torch==1.9.1, but you have torch 1.10.0 which is incompatible.\n",
            "torchaudio 0.9.1 requires torch==1.9.1, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0 torchtext-0.11.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/home/ckm/python3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PSSRsC1fNADr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muafgoq3zdah",
        "outputId": "cd656d64-7473-458b-a6ed-4d04a16d7ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov  2 23:21:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-PCIE...  On   | 00000000:17:00.0 Off |                    0 |\n",
            "| N/A   71C    P0    55W / 250W |   6819MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1094      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    0   N/A  N/A     21651      C   .../ckm/python3.7/bin/python     6811MiB |\n",
            "+-----------------------------------------------------------------------------+\n",
            "WARNING: infoROM is corrupted at gpu 0000:17:00.0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4B0ARAXTkLp"
      },
      "source": [
        "### Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HzzoO4vmNW1V"
      },
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xba in position 0: invalid start byte",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_7052/1236000568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/ckm/ck_project/data/YouTubeComments/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"mal_eng_emb.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m~/python3.7/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xba in position 0: invalid start byte"
          ]
        }
      ],
      "source": [
        "datapath = \"/home/ckm/ck_project/data/YouTubeComments/\"\n",
        "df_embedding = pd.read_csv(datapath+\"mal_eng_emb.bin\", sep=\" \", quoting=3, header=None, index_col=0,skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 759 kB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.8.1-py2.py3-none-any.whl (208 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /home/ckm/python3.7/lib/python3.7/site-packages (from fasttext) (47.1.0)\n",
            "Requirement already satisfied: numpy in /home/ckm/python3.7/lib/python3.7/site-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
            "   command: /home/ckm/python3.7/bin/python3.7 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-kb2odqlo\n",
            "       cwd: /tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/\n",
            "  Complete output (38 lines):\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.7\n",
            "  creating build/lib.linux-x86_64-3.7/fasttext\n",
            "  copying python/fasttext_module/fasttext/FastText.py -> build/lib.linux-x86_64-3.7/fasttext\n",
            "  copying python/fasttext_module/fasttext/__init__.py -> build/lib.linux-x86_64-3.7/fasttext\n",
            "  creating build/lib.linux-x86_64-3.7/fasttext/util\n",
            "  copying python/fasttext_module/fasttext/util/util.py -> build/lib.linux-x86_64-3.7/fasttext/util\n",
            "  copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.linux-x86_64-3.7/fasttext/util\n",
            "  creating build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "  copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "  copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "  copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "  running build_ext\n",
            "  creating tmp\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/ckm/python3.7/include -I/usr/include/python3.7m -c /tmp/tmpyomtcgyo.cpp -o tmp/tmpyomtcgyo.o -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/ckm/python3.7/include -I/usr/include/python3.7m -c /tmp/tmpy3cp2yc4.cpp -o tmp/tmpy3cp2yc4.o -fvisibility=hidden\n",
            "  building 'fasttext_pybind' extension\n",
            "  creating build/temp.linux-x86_64-3.7\n",
            "  creating build/temp.linux-x86_64-3.7/python\n",
            "  creating build/temp.linux-x86_64-3.7/python/fasttext_module\n",
            "  creating build/temp.linux-x86_64-3.7/python/fasttext_module/fasttext\n",
            "  creating build/temp.linux-x86_64-3.7/python/fasttext_module/fasttext/pybind\n",
            "  creating build/temp.linux-x86_64-3.7/src\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include -I/home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include -Isrc -I/home/ckm/python3.7/include -I/usr/include/python3.7m -c python/fasttext_module/fasttext/pybind/fasttext_pybind.cc -o build/temp.linux-x86_64-3.7/python/fasttext_module/fasttext/pybind/fasttext_pybind.o -DVERSION_INFO=\"0.9.2\" -std=c++14 -fvisibility=hidden\n",
            "  In file included from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/pytypes.h:12:0,\n",
            "                   from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/cast.h:13,\n",
            "                   from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/attr.h:13,\n",
            "                   from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/pybind11.h:13,\n",
            "                   from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/numpy.h:12,\n",
            "                   from python/fasttext_module/fasttext/pybind/fasttext_pybind.cc:13:\n",
            "  /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/detail/common.h:186:10: fatal error: Python.h: No such file or directory\n",
            "   #include <Python.h>\n",
            "            ^~~~~~~~~~\n",
            "  compilation terminated.\n",
            "  error: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n",
            "  ----------------------------------------\u001b[0m\n",
            "\u001b[31m  ERROR: Failed building wheel for fasttext\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for fasttext\n",
            "Failed to build fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "    Running setup.py install for fasttext ... \u001b[?25lerror\n",
            "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
            "     command: /home/ckm/python3.7/bin/python3.7 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-p78nu9a8/install-record.txt --single-version-externally-managed --compile --install-headers /home/ckm/python3.7/include/site/python3.7/fasttext\n",
            "         cwd: /tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/\n",
            "    Complete output (37 lines):\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.7\n",
            "    creating build/lib.linux-x86_64-3.7/fasttext\n",
            "    copying python/fasttext_module/fasttext/FastText.py -> build/lib.linux-x86_64-3.7/fasttext\n",
            "    copying python/fasttext_module/fasttext/__init__.py -> build/lib.linux-x86_64-3.7/fasttext\n",
            "    creating build/lib.linux-x86_64-3.7/fasttext/util\n",
            "    copying python/fasttext_module/fasttext/util/util.py -> build/lib.linux-x86_64-3.7/fasttext/util\n",
            "    copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.linux-x86_64-3.7/fasttext/util\n",
            "    creating build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "    copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "    copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "    copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.linux-x86_64-3.7/fasttext/tests\n",
            "    running build_ext\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/ckm/python3.7/include -I/usr/include/python3.7m -c /tmp/tmpal1pgwdx.cpp -o tmp/tmpal1pgwdx.o -std=c++14\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/ckm/python3.7/include -I/usr/include/python3.7m -c /tmp/tmpxi0o0rpt.cpp -o tmp/tmpxi0o0rpt.o -fvisibility=hidden\n",
            "    building 'fasttext_pybind' extension\n",
            "    creating build/temp.linux-x86_64-3.7\n",
            "    creating build/temp.linux-x86_64-3.7/python\n",
            "    creating build/temp.linux-x86_64-3.7/python/fasttext_module\n",
            "    creating build/temp.linux-x86_64-3.7/python/fasttext_module/fasttext\n",
            "    creating build/temp.linux-x86_64-3.7/python/fasttext_module/fasttext/pybind\n",
            "    creating build/temp.linux-x86_64-3.7/src\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include -I/home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include -Isrc -I/home/ckm/python3.7/include -I/usr/include/python3.7m -c python/fasttext_module/fasttext/pybind/fasttext_pybind.cc -o build/temp.linux-x86_64-3.7/python/fasttext_module/fasttext/pybind/fasttext_pybind.o -DVERSION_INFO=\"0.9.2\" -std=c++14 -fvisibility=hidden\n",
            "    In file included from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/pytypes.h:12:0,\n",
            "                     from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/cast.h:13,\n",
            "                     from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/attr.h:13,\n",
            "                     from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/pybind11.h:13,\n",
            "                     from /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/numpy.h:12,\n",
            "                     from python/fasttext_module/fasttext/pybind/fasttext_pybind.cc:13:\n",
            "    /home/ckm/python3.7/lib/python3.7/site-packages/pybind11/include/pybind11/detail/common.h:186:10: fatal error: Python.h: No such file or directory\n",
            "     #include <Python.h>\n",
            "              ^~~~~~~~~~\n",
            "    compilation terminated.\n",
            "    error: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n",
            "    ----------------------------------------\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Command errored out with exit status 1: /home/ckm/python3.7/bin/python3.7 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-xc7xqyqn/fasttext_5561fbcb2034470c8a5b3e65c0d23421/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-p78nu9a8/install-record.txt --single-version-externally-managed --compile --install-headers /home/ckm/python3.7/include/site/python3.7/fasttext Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/home/ckm/python3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "datapath = \"/home/ckm/ck_project/data/YouTubeComments/mal_eng_emb.bin\"\n",
        "\n",
        "ft = fasttext.load_model(datapath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2Wnirn_1ERuU",
        "outputId": "94f9f804-6f56-40c5-b8cb-6c083d841b70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nahi</th>\n",
              "      <td>-0.079912</td>\n",
              "      <td>0.522077</td>\n",
              "      <td>0.009111</td>\n",
              "      <td>-0.103475</td>\n",
              "      <td>-0.042439</td>\n",
              "      <td>0.229031</td>\n",
              "      <td>0.360524</td>\n",
              "      <td>0.047913</td>\n",
              "      <td>0.129397</td>\n",
              "      <td>0.184819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049488</td>\n",
              "      <td>-0.291750</td>\n",
              "      <td>0.188353</td>\n",
              "      <td>-0.099099</td>\n",
              "      <td>0.271938</td>\n",
              "      <td>0.311072</td>\n",
              "      <td>-0.446256</td>\n",
              "      <td>-0.093532</td>\n",
              "      <td>0.118786</td>\n",
              "      <td>-0.221102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.268486</td>\n",
              "      <td>0.454443</td>\n",
              "      <td>-0.211620</td>\n",
              "      <td>-0.029896</td>\n",
              "      <td>-0.123828</td>\n",
              "      <td>0.119760</td>\n",
              "      <td>0.146776</td>\n",
              "      <td>0.152356</td>\n",
              "      <td>0.136670</td>\n",
              "      <td>-0.086144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.256750</td>\n",
              "      <td>0.170485</td>\n",
              "      <td>-0.081619</td>\n",
              "      <td>-0.110159</td>\n",
              "      <td>-0.012980</td>\n",
              "      <td>0.211806</td>\n",
              "      <td>-0.197437</td>\n",
              "      <td>0.094797</td>\n",
              "      <td>-0.070250</td>\n",
              "      <td>-0.186570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ki</th>\n",
              "      <td>-0.342798</td>\n",
              "      <td>0.568509</td>\n",
              "      <td>0.049298</td>\n",
              "      <td>-0.111945</td>\n",
              "      <td>-0.312412</td>\n",
              "      <td>0.490620</td>\n",
              "      <td>0.442846</td>\n",
              "      <td>0.053863</td>\n",
              "      <td>0.177461</td>\n",
              "      <td>0.111002</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491238</td>\n",
              "      <td>-0.074531</td>\n",
              "      <td>0.165319</td>\n",
              "      <td>-0.015633</td>\n",
              "      <td>0.151389</td>\n",
              "      <td>0.332968</td>\n",
              "      <td>-0.311262</td>\n",
              "      <td>0.057184</td>\n",
              "      <td>-0.281329</td>\n",
              "      <td>-0.346765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ke</th>\n",
              "      <td>-0.299528</td>\n",
              "      <td>0.510413</td>\n",
              "      <td>-0.033908</td>\n",
              "      <td>-0.064933</td>\n",
              "      <td>-0.439092</td>\n",
              "      <td>0.359395</td>\n",
              "      <td>0.342511</td>\n",
              "      <td>-0.102557</td>\n",
              "      <td>0.354761</td>\n",
              "      <td>0.632507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202599</td>\n",
              "      <td>-0.206487</td>\n",
              "      <td>0.178269</td>\n",
              "      <td>-0.108783</td>\n",
              "      <td>0.322591</td>\n",
              "      <td>0.347032</td>\n",
              "      <td>-0.558663</td>\n",
              "      <td>-0.018923</td>\n",
              "      <td>0.116121</td>\n",
              "      <td>-0.325165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>se</th>\n",
              "      <td>-0.435697</td>\n",
              "      <td>0.357603</td>\n",
              "      <td>-0.040995</td>\n",
              "      <td>0.107330</td>\n",
              "      <td>-0.313671</td>\n",
              "      <td>0.268082</td>\n",
              "      <td>0.246396</td>\n",
              "      <td>0.005616</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>0.249072</td>\n",
              "      <td>...</td>\n",
              "      <td>0.409665</td>\n",
              "      <td>-0.106801</td>\n",
              "      <td>-0.285788</td>\n",
              "      <td>0.028810</td>\n",
              "      <td>0.064475</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>-0.666445</td>\n",
              "      <td>-0.167434</td>\n",
              "      <td>-0.310887</td>\n",
              "      <td>-0.367422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           1         2         3         4         5         6         7    \\\n",
              "0                                                                            \n",
              "nahi -0.079912  0.522077  0.009111 -0.103475 -0.042439  0.229031  0.360524   \n",
              "to    0.268486  0.454443 -0.211620 -0.029896 -0.123828  0.119760  0.146776   \n",
              "ki   -0.342798  0.568509  0.049298 -0.111945 -0.312412  0.490620  0.442846   \n",
              "ke   -0.299528  0.510413 -0.033908 -0.064933 -0.439092  0.359395  0.342511   \n",
              "se   -0.435697  0.357603 -0.040995  0.107330 -0.313671  0.268082  0.246396   \n",
              "\n",
              "           8         9         10   ...       91        92        93   \\\n",
              "0                                   ...                                 \n",
              "nahi  0.047913  0.129397  0.184819  ...  0.049488 -0.291750  0.188353   \n",
              "to    0.152356  0.136670 -0.086144  ...  0.256750  0.170485 -0.081619   \n",
              "ki    0.053863  0.177461  0.111002  ...  0.491238 -0.074531  0.165319   \n",
              "ke   -0.102557  0.354761  0.632507  ...  0.202599 -0.206487  0.178269   \n",
              "se    0.005616  0.089185  0.249072  ...  0.409665 -0.106801 -0.285788   \n",
              "\n",
              "           94        95        96        97        98        99        100  \n",
              "0                                                                           \n",
              "nahi -0.099099  0.271938  0.311072 -0.446256 -0.093532  0.118786 -0.221102  \n",
              "to   -0.110159 -0.012980  0.211806 -0.197437  0.094797 -0.070250 -0.186570  \n",
              "ki   -0.015633  0.151389  0.332968 -0.311262  0.057184 -0.281329 -0.346765  \n",
              "ke   -0.108783  0.322591  0.347032 -0.558663 -0.018923  0.116121 -0.325165  \n",
              "se    0.028810  0.064475  0.117800 -0.666445 -0.167434 -0.310887 -0.367422  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_embedding.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJaOLL02TmUy"
      },
      "source": [
        "### Create vocab dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456blVxHEqJK",
        "outputId": "1fabfa5e-e9db-40dc-ab0d-d166d43011d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = df_embedding.to_numpy()\n",
        "m.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKURV7-5NXfE",
        "outputId": "aa55221f-8b72-43cf-ead5-c93cc46fc391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix = df_embedding.to_numpy()\n",
        "\n",
        "vocab = []\n",
        "\n",
        "for word in list(df_embedding.index):\n",
        "  vocab.append(str(word))\n",
        "\n",
        "vocab_size , vocab_dim = embedding_matrix.shape\n",
        "vocab_size, vocab_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHZGs3aFF6b",
        "outputId": "a2d76acf-4109-40cb-f952-a38c12680201"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40599"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Rju-5mvbVp6H"
      },
      "outputs": [],
      "source": [
        "word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY77Ru_NFMMs",
        "outputId": "45e84371-3f06-494c-dfb6-4ec87e2edd77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40598, 40599)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2idx) , len(idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBRDCquFF62W",
        "outputId": "ce912395-b2d0-479c-d114-549f630f681d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nahi': 0,\n",
              " 'to': 1,\n",
              " 'ki': 2,\n",
              " 'ke': 3,\n",
              " 'se': 4,\n",
              " 'ko': 5,\n",
              " 'the': 6,\n",
              " 'ka': 7,\n",
              " 'me': 8,\n",
              " 'bhi': 9}"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "dict(itertools.islice(word2idx.items(), 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0HS8bPTqWq"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "pbzhx5a0m_Sr"
      },
      "outputs": [],
      "source": [
        "def sub_one(x):\n",
        "\treturn x - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSukKoeeNvSs",
        "outputId": "ac5d640e-fe25-4325-8fd9-cda5c59e06d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6800 6800\n",
            "1500 1500\n",
            "1500 1500\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/home/ckm/ck_project/data/YouTubeComments/Youtube_Comments_Data.csv')\n",
        "df= df.sample(frac = 1)\n",
        "\n",
        "df['Labels'] = df['Labels'].apply(sub_one)\n",
        "\n",
        "train_df = df[:6800]\n",
        "val_df = df[6800:8300]\n",
        "test_df = df[8300:]\n",
        "\n",
        "train_df.head()\n",
        "\n",
        "\n",
        "train_data =  train_df['commentText'].values\n",
        "train_labels = train_df['Labels'].values\n",
        "\n",
        "val_data =  val_df['commentText'].values\n",
        "val_labels = val_df['Labels'].values\n",
        "\n",
        "test_data =  test_df['commentText'].values\n",
        "test_labels = test_df['Labels'].values\n",
        "\n",
        "print(len(train_data), len(train_labels))\n",
        "print(len(val_data), len(val_labels))\n",
        "print(len(test_data), len(test_labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FMJNuKrDn-xb",
        "outputId": "0d136085-6d5e-44c5-c7ae-13f046263e35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>commentText</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4624</th>\n",
              "      <td>UgiA39qPyH10dXgCoAEC</td>\n",
              "      <td>I  like all your video</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9007</th>\n",
              "      <td>UghH5-f7-yD9TXgCoAEC</td>\n",
              "      <td>Not only this but all of ur videos are fantast...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6144</th>\n",
              "      <td>UgySwXfwwyBAFUVQj4l4AaABAg</td>\n",
              "      <td>Mai bhaut badhi fan ho Kyu ki aap accha cooker...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1772</th>\n",
              "      <td>UgiDWrc-fBhpvXgCoAEC</td>\n",
              "      <td>thank for recipe k liye</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7521</th>\n",
              "      <td>Ugxa-76nU2Ak3A0GzGV4AaABAg</td>\n",
              "      <td>Nice</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id  \\\n",
              "4624        UgiA39qPyH10dXgCoAEC   \n",
              "9007        UghH5-f7-yD9TXgCoAEC   \n",
              "6144  UgySwXfwwyBAFUVQj4l4AaABAg   \n",
              "1772        UgiDWrc-fBhpvXgCoAEC   \n",
              "7521  Ugxa-76nU2Ak3A0GzGV4AaABAg   \n",
              "\n",
              "                                            commentText  Labels  \n",
              "4624                             I  like all your video       3  \n",
              "9007  Not only this but all of ur videos are fantast...       4  \n",
              "6144  Mai bhaut badhi fan ho Kyu ki aap accha cooker...       3  \n",
              "1772                            thank for recipe k liye       0  \n",
              "7521                                               Nice       2  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "83AlL80DN1_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# post = pd.read_csv(\"positive_add1and2.csv\",sep=',')\n",
        "# neg = pd.read_csv(\"negative_add_1and2.csv\",sep=',')\n",
        "\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "# for index, row in post.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(1)\n",
        "\n",
        "\n",
        "# for index, row in neg.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(0)\n",
        "  \n",
        "\n",
        "# len(data), len(labels)\n",
        "\n",
        "# data, labels  = shuffle(data, labels, random_state = 40)\n",
        "\n",
        "# data[0], labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5iYXAJbTwJ8"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "QgF5Hb8weYwB"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "\n",
        "def tokenized_tensor(data):\n",
        "\n",
        "  output_tokenized = []\n",
        "\n",
        "  for sentence in data:\n",
        "    output = []\n",
        "    tokenized = tokenizer(sentence)\n",
        "    \n",
        "    for word in tokenized:\n",
        "      if word in word2idx:\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "      else:\n",
        "        word2idx[word] = len(word2idx)\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "\n",
        "    output = torch.tensor(output)\n",
        "\n",
        "\n",
        "    output_tokenized.append(output)\n",
        "\n",
        "  return output_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "K_pDpPLhiUPG"
      },
      "outputs": [],
      "source": [
        "# tokenized_sequences = tokenized_tensor(data)\n",
        "\n",
        "train_tokenized_sequences = tokenized_tensor(train_data)\n",
        "\n",
        "test_tokenized_seuqences = tokenized_tensor(test_data)\n",
        "\n",
        "val_tokenized_seuquences = tokenized_tensor(val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6WOxrifIFKQ",
        "outputId": "ef207cd4-55fc-456f-bc8e-adaadbe1cc96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([   78,   229,    55,    93,    87,    14,   517,  2291,    47,  5417,\n",
            "        40598,   221,   130,  5814,   169,    10,   506,    15,   420,  1915,\n",
            "          126,   172,  2222,  5623, 40598, 40598, 40598,  1172,   491,   409,\n",
            "          221, 23572, 23572,   491,   507,  3190, 40598, 40598, 40598, 40598,\n",
            "        40598])\n"
          ]
        }
      ],
      "source": [
        "print(train_tokenized_sequences[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poFrSB5Opl1-",
        "outputId": "0bad193a-cf73-4f71-e6e9-509bfec95058"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44838"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2idx['<PAD>'] = len(word2idx)\n",
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9AZYccLbVof",
        "outputId": "bf73d6d9-113b-4880-9a85-a27c29d13ae9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44839"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "GYstutbgrABv"
      },
      "outputs": [],
      "source": [
        "## Create embedding matrix\n",
        "\n",
        "random_init = torch.nn.Parameter(torch.Tensor( (len(word2idx) - vocab_size), vocab_dim))\n",
        "torch.nn.init.kaiming_uniform_(random_init, a=math.sqrt(5))\n",
        "\n",
        "\n",
        "new_matrix = np.zeros( (len(word2idx), vocab_dim) )\n",
        "\n",
        "new_matrix[:vocab_size, :] = embedding_matrix\n",
        "\n",
        "embedding_matrix = new_matrix\n",
        "\n",
        "embedding_matrix[vocab_size:, :] = random_init.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0mL0x6J3KV",
        "outputId": "32d4bf4d-7ec2-4085-fce3-6c7b82f0922a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44839, 100)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "3cp0nnNdrazK"
      },
      "outputs": [],
      "source": [
        "# padded_sequences = pad_sequence(tokenized_sequences, batch_first= True, padding_value=107512)\n",
        "\n",
        "train_padded_sequences = pad_sequence(train_tokenized_sequences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "val_padded_sequences = pad_sequence(val_tokenized_seuquences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "test_padded_sequences = pad_sequence(test_tokenized_seuqences, batch_first= True, padding_value=word2idx['<PAD>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trl1D4QFII3e",
        "outputId": "281787e8-4bbd-4b9c-dea0-6f937b0b3f9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([   78,   229,    55,    93,    87,    14,   517,  2291,    47,  5417,\n",
              "        40598,   221,   130,  5814,   169,    10,   506,    15,   420,  1915,\n",
              "          126,   172,  2222,  5623, 40598, 40598, 40598,  1172,   491,   409,\n",
              "          221, 23572, 23572,   491,   507,  3190, 40598, 40598, 40598, 40598,\n",
              "        40598, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "        44838, 44838])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_padded_sequences[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSE4xlb2O8Ju"
      },
      "source": [
        "### Dataset and Data loader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ISg-6szPOBr1"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
        "    \"\"\"\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.labels = labels\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        sequence = self.sequences[idx]\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        try:\n",
        "            sample[\"label\"] = label\n",
        "            sample[\"token\"] = sequence\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "L1LEy0ogII3g"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_padded_sequences, train_labels)\n",
        "\n",
        "val_dataset = Dataset(val_padded_sequences, val_labels)\n",
        "\n",
        "test_dataset = Dataset(test_padded_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQVUtYvII3g"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC2nFBOTynbR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ENWuqJHeII3h"
      },
      "outputs": [],
      "source": [
        "## Hyper parameter\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "embed_dim = vocab_dim\n",
        "seq_len = 192\n",
        "hidden_size = 512\n",
        "num_layer = 3\n",
        "num_class = 7\n",
        "batch_size = 32\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 30\n",
        "CLIP = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "R2daJrk6PQb7"
      },
      "outputs": [],
      "source": [
        "# # Create datasets\n",
        "# dataset = Dataset(padded_sequences, labels)\n",
        "\n",
        "# split = 0.85\n",
        "# train_size = int(split*len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "LSYO1yrqPSgn"
      },
      "outputs": [],
      "source": [
        "\n",
        "## We call the dataloader class\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "## For testing\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "\n",
        "dataloaders = {'Train': train_loader, 'Val': val_loader}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ZYd39BII3i",
        "outputId": "3a10a91c-2116-4ada-e1f6-e3abc17ea147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(212, 46, 46)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoA6yF7iomTV",
        "outputId": "418e1523-d735-4082-f963-16580e8ea844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65\n"
          ]
        }
      ],
      "source": [
        "max_len = -1\n",
        "for comment in val_dataset:\n",
        "  sentence = comment['token']\n",
        "  max_len = max(max_len,sentence.shape[0])\n",
        "\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0DXO4Q2II3i",
        "outputId": "471b3762-68ba-4ac6-8f4c-2acd20a5b427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'label': tensor(3),\n",
              " 'token': tensor([  162,    73,    87,    94,   383, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838, 44838,\n",
              "         44838, 44838])}"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXQNerMvjIb"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "wR0tnE2NxphD"
      },
      "outputs": [],
      "source": [
        "class SelfMatchingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,  seq_length, embed_dim, **kwargs):\n",
        "\n",
        "      super(SelfMatchingLayer, self).__init__()\n",
        "\n",
        "      self.seq_length = seq_length\n",
        "      self.embed_dim  = embed_dim\n",
        "\n",
        "      self.P = torch.nn.Parameter(torch.Tensor(self.embed_dim, self.embed_dim))\n",
        "\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.P, a=math.sqrt(5))\n",
        "\n",
        "      \n",
        "    def forward(self, x):  \n",
        "      \n",
        "      # input shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "\n",
        "      #---------------------------------------------#\n",
        "      # calculate weight vector a = {e_i . P.Q . e_j}\n",
        "      #---------------------------------------------#\n",
        "\n",
        "      out = torch.matmul(x,  self.P)   #out shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "      out = torch.matmul(out, torch.transpose(x, 1, 2))   #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = F.gelu(out)         # apply non linear activation\n",
        "\n",
        "      #------------------------------------#\n",
        "      # take row wise mean and apply softmax\n",
        "      #------------------------------------#\n",
        "      out = torch.mean(out, 2)  #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = torch.softmax(out, 0)     #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = out.unsqueeze(1)          #out shape: [batch, 1, seq_len]\n",
        "\n",
        "      #-------------------------------------------#\n",
        "      # calculate weighted embedding of every word\n",
        "      #-------------------------------------------#\n",
        "      out = torch.matmul(out, x)\n",
        "\n",
        "      out = out.squeeze(1)\n",
        "\n",
        "      return out      #out shape: [batch, seq_len]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkC2PE1q3Fq",
        "outputId": "5188e8ce-3efa-4280-f761-511c46f26e2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44838"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "LFAeZSyXu9KJ"
      },
      "outputs": [],
      "source": [
        "class SelfNet(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class):\n",
        "        super(SelfNet, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = word2idx['<PAD>'])\n",
        "        self.embedding.load_state_dict({'weight': torch.from_numpy(embedding_matrix)})\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        self.selfnet_layer = SelfMatchingLayer(seq_len, embed_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = num_layer, dropout = 0.3, bidirectional = True, batch_first = True )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2* hidden_size + embed_dim , hidden_size//4)\n",
        "        self.fc2 = nn.Linear(hidden_size//4, num_class)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        embedded = self.embedding(input)  #out shape = [batch, seq_len, embed_dim] \n",
        "\n",
        "        selfmatch_output = self.selfnet_layer(embedded)  #out shape = [batch, seq_len] \n",
        "\n",
        "        lstm_out, _ = self.lstm(embedded)     \n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]      #out shape = [batch, 2 * hidden_size]      \n",
        "\n",
        "        concat = torch.cat( (selfmatch_output, lstm_out), 1)     #out shape = [batch, 2 * hidden_size + seq_len ]      \n",
        "\n",
        "        linear_out = self.dropout(F.relu(self.fc1(concat)))     #out shape = [batch, hidden_size]      \n",
        "\n",
        "        final_out = self.fc2(linear_out)     #out shape = [batch, 2]      \n",
        "\n",
        "        return final_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Msc1-1zlOtAh"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Test\n",
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\n",
        "model = model.to(device)\n",
        "\n",
        "# for batch in train_loader:\n",
        "#   x = batch['token'].to(device)\n",
        "#   out = model(x)\n",
        "#   print(out.shape)\n",
        "#   break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-XvE3WHII3l",
        "outputId": "aaf727e6-066f-49bc-d07b-e32dfa27a9a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xjqPfmqx5Hj"
      },
      "source": [
        "### Optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "ifFhRpc2x4Fv"
      },
      "outputs": [],
      "source": [
        "#optimizer\n",
        "optimizer = Adam(model.parameters(), lr = LEARNING_RATE, eps=1e-8)\n",
        "#Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "04ozLaUUx-eo"
      },
      "outputs": [],
      "source": [
        "#to calculate accuracy\n",
        "\n",
        "def get_accuracy(preds, labels):\n",
        "  total_acc = 0.0\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    if labels[i] == preds[i]:\n",
        "      total_acc+=1.0\n",
        "  \n",
        "  return total_acc / len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D33SEPjzILZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP5of6JbII3n",
        "outputId": "58296fc2-81e5-4394-eec6-d979870d53b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5, verbose = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "2o0-BUMKII3o"
      },
      "outputs": [],
      "source": [
        "PATH = '/home/ckm/ck_project/codemix/code/selfnet_mihir/models/selfnet_mean+gelu_2_mihir_yt_1.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZkPq1t6yBwx",
        "outputId": "4a678302-dc2f-421d-a886-c7448087ca26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:54<00:00,  3.87batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5169, Precision: 0.5312, Recall : 0.5397, Accuracy: 0.5397, Loss: 0.0111.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.2853, Precision: 0.3340, Recall : 0.3546, Accuracy: 0.3546, Loss: 0.0637.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:54<00:00,  3.87batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5602, Precision: 0.5702, Recall : 0.5777, Accuracy: 0.5777, Loss: 0.0087.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.3723, Precision: 0.3914, Recall : 0.4137, Accuracy: 0.4137, Loss: 0.0663.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:55<00:00,  3.84batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5909, Precision: 0.5985, Recall : 0.6038, Accuracy: 0.6038, Loss: 0.0102.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.3707, Precision: 0.3889, Recall : 0.4212, Accuracy: 0.4212, Loss: 0.0558.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.78batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.6299, Precision: 0.6359, Recall : 0.6414, Accuracy: 0.6414, Loss: 0.0067.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.3908, Precision: 0.4065, Recall : 0.4409, Accuracy: 0.4409, Loss: 0.0592.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.6708, Precision: 0.6765, Recall : 0.6797, Accuracy: 0.6797, Loss: 0.0101.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4434, Precision: 0.5016, Recall : 0.4939, Accuracy: 0.4939, Loss: 0.0494.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:55<00:00,  3.79batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7072, Precision: 0.7114, Recall : 0.7133, Accuracy: 0.7133, Loss: 0.0068.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4470, Precision: 0.4714, Recall : 0.4952, Accuracy: 0.4952, Loss: 0.0463.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7368, Precision: 0.7405, Recall : 0.7416, Accuracy: 0.7416, Loss: 0.0068.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4496, Precision: 0.5055, Recall : 0.4973, Accuracy: 0.4973, Loss: 0.0460.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7674, Precision: 0.7691, Recall : 0.7705, Accuracy: 0.7705, Loss: 0.0061.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.5252, Precision: 0.5867, Recall : 0.5469, Accuracy: 0.5469, Loss: 0.0458.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.73batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7976, Precision: 0.8003, Recall : 0.7998, Accuracy: 0.7998, Loss: 0.0074.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6572, Precision: 0.6762, Recall : 0.6529, Accuracy: 0.6529, Loss: 0.0318.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8187, Precision: 0.8210, Recall : 0.8206, Accuracy: 0.8206, Loss: 0.0044.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6479, Precision: 0.6700, Recall : 0.6447, Accuracy: 0.6447, Loss: 0.0334.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8388, Precision: 0.8409, Recall : 0.8402, Accuracy: 0.8402, Loss: 0.0053.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6835, Precision: 0.6900, Recall : 0.6841, Accuracy: 0.6841, Loss: 0.0323.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.73batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8585, Precision: 0.8595, Recall : 0.8595, Accuracy: 0.8595, Loss: 0.0059.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6614, Precision: 0.6844, Recall : 0.6583, Accuracy: 0.6583, Loss: 0.0355.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8712, Precision: 0.8725, Recall : 0.8722, Accuracy: 0.8722, Loss: 0.0027.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6779, Precision: 0.6882, Recall : 0.6766, Accuracy: 0.6766, Loss: 0.0321.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:55<00:00,  3.79batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8821, Precision: 0.8830, Recall : 0.8831, Accuracy: 0.8831, Loss: 0.0034.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6863, Precision: 0.7070, Recall : 0.6868, Accuracy: 0.6868, Loss: 0.0334.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8981, Precision: 0.8989, Recall : 0.8989, Accuracy: 0.8989, Loss: 0.0032.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.18batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6880, Precision: 0.7036, Recall : 0.6861, Accuracy: 0.6861, Loss: 0.0733.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.74batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9055, Precision: 0.9057, Recall : 0.9061, Accuracy: 0.9061, Loss: 0.0012.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6993, Precision: 0.7095, Recall : 0.6970, Accuracy: 0.6970, Loss: 0.0489.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9166, Precision: 0.9167, Recall : 0.9170, Accuracy: 0.9170, Loss: 0.0056.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7023, Precision: 0.7180, Recall : 0.7004, Accuracy: 0.7004, Loss: 0.0431.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.79batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9232, Precision: 0.9234, Recall : 0.9235, Accuracy: 0.9235, Loss: 0.0008.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6923, Precision: 0.7024, Recall : 0.6902, Accuracy: 0.6902, Loss: 0.0396.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9284, Precision: 0.9287, Recall : 0.9288, Accuracy: 0.9288, Loss: 0.0015.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7060, Precision: 0.7112, Recall : 0.7045, Accuracy: 0.7045, Loss: 0.0601.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9336, Precision: 0.9337, Recall : 0.9338, Accuracy: 0.9338, Loss: 0.0012.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7155, Precision: 0.7235, Recall : 0.7126, Accuracy: 0.7126, Loss: 0.0667.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9370, Precision: 0.9370, Recall : 0.9372, Accuracy: 0.9372, Loss: 0.0020.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7158, Precision: 0.7227, Recall : 0.7133, Accuracy: 0.7133, Loss: 0.0289.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.78batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9419, Precision: 0.9419, Recall : 0.9421, Accuracy: 0.9421, Loss: 0.0031.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7100, Precision: 0.7226, Recall : 0.7072, Accuracy: 0.7072, Loss: 0.0490.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9445, Precision: 0.9446, Recall : 0.9447, Accuracy: 0.9447, Loss: 0.0016.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7187, Precision: 0.7298, Recall : 0.7147, Accuracy: 0.7147, Loss: 0.0324.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9517, Precision: 0.9517, Recall : 0.9518, Accuracy: 0.9518, Loss: 0.0011.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7032, Precision: 0.7157, Recall : 0.6997, Accuracy: 0.6997, Loss: 0.0516.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.78batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9571, Precision: 0.9572, Recall : 0.9573, Accuracy: 0.9573, Loss: 0.0008.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7113, Precision: 0.7224, Recall : 0.7086, Accuracy: 0.7086, Loss: 0.0395.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9580, Precision: 0.9581, Recall : 0.9581, Accuracy: 0.9581, Loss: 0.0006.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7232, Precision: 0.7333, Recall : 0.7215, Accuracy: 0.7215, Loss: 0.0353.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.74batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9532, Precision: 0.9533, Recall : 0.9533, Accuracy: 0.9533, Loss: 0.0018.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7206, Precision: 0.7334, Recall : 0.7181, Accuracy: 0.7181, Loss: 0.0747.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9597, Precision: 0.9597, Recall : 0.9598, Accuracy: 0.9598, Loss: 0.0020.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7276, Precision: 0.7326, Recall : 0.7262, Accuracy: 0.7262, Loss: 0.0766.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:55<00:00,  3.81batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9613, Precision: 0.9613, Recall : 0.9614, Accuracy: 0.9614, Loss: 0.0007.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7233, Precision: 0.7310, Recall : 0.7208, Accuracy: 0.7208, Loss: 0.0226.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9648, Precision: 0.9649, Recall : 0.9649, Accuracy: 0.9649, Loss: 0.0012.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7373, Precision: 0.7415, Recall : 0.7371, Accuracy: 0.7371, Loss: 0.0605.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ],
      "source": [
        "best_valid_f1 = 0.0000\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "  \n",
        "\n",
        "    print('-'*50)\n",
        "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
        "\n",
        "    for phase in ['Train', 'Val']:\n",
        "\n",
        "        loss = 0.0   #epoch loss\n",
        "        accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        if phase == 'Train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        \n",
        "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
        "\n",
        "          for batch in tepoch:\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            text = batch[\"token\"].to(device)\n",
        "            \n",
        "\n",
        "            output = model(text)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            if phase == 'Train':\n",
        "\n",
        "                #zero gradients\n",
        "                optimizer.zero_grad() \n",
        "\n",
        "                # Backward pass  (calculates the gradients)\n",
        "                loss.backward()   \n",
        "\n",
        "                # gradient clipping\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
        "\n",
        "                optimizer.step()             # Updates the weights    \n",
        "\n",
        "            sleep(0.1)\n",
        "            _, preds = output.data.max(1)\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "            \n",
        "            batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "            \n",
        "            \n",
        "            loss += loss.item()\n",
        "            accuracy+= batch_acc\n",
        "\n",
        "              \n",
        "          epoch_loss = loss / (len(dataloaders[phase]))\n",
        "          epoch_acc = accuracy / (len(dataloaders[phase]))\n",
        "\n",
        "          print(phase + \":\")\n",
        "          \n",
        "          \n",
        "          #print(confusion_matrix(y_true, y_pred))\n",
        "          pre = precision_score(y_true, y_pred, average='weighted')\n",
        "          recall = recall_score(y_true, y_pred, average='weighted')\n",
        "          f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "          \n",
        "\n",
        "          print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))\n",
        "          # save best model\n",
        "          print()\n",
        "          \n",
        "            \n",
        "          if phase == 'Val':\n",
        "                \n",
        "                if f1 > best_valid_f1:\n",
        "                    best_valid_f1 = f1\n",
        "                    \n",
        "                    torch.save(model.state_dict(), PATH)\n",
        "                    print('Model Saved!')\n",
        "                    \n",
        "                scheduler.step()\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yJchRvUz2nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsq5MiaHII3r"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "0L66ZUsoII3r"
      },
      "outputs": [],
      "source": [
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "EceKQVWTII3r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "A1DB4Su5II3r"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  7.70batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[154   1   3   2  40  11   0]\n",
            " [  1 145  16   7  20  13   0]\n",
            " [  0  12 191   3   3   3   0]\n",
            " [  3   2   7 147  37  15   2]\n",
            " [ 18  10   2   9 159   7   0]\n",
            " [  5   9  11  15   3 150  33]\n",
            " [  2   2   2   0   0  36 161]]\n",
            "\n",
            "F1: 0.7520, Precision: 0.7520, Recall : 0.7520, Accuracy: 0.7520, Loss: 0.0856.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "X99rC-LvII3s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "EQwRQc_NII3s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:06<00:00,  7.66batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[148   1   3   2  41  14   0]\n",
            " [  1 141  16   8  23  15   0]\n",
            " [  0  12 194   2   3   4   0]\n",
            " [  3   3   6 151  32  19   1]\n",
            " [ 17   9   2   8 162   6   1]\n",
            " [  5   9  11  15   3 145  35]\n",
            " [  1   2   2   0   0  36 160]]\n",
            "\n",
            "F1: 0.7493, Precision: 0.7584, Recall : 0.7480, Accuracy: 0.7480, Loss: 0.0303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "wQs04_VAII3t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  7.70batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[147   1   3   2  43  14   0]\n",
            " [  0 144  15   7  24  12   1]\n",
            " [  0   9 195   3   3   4   0]\n",
            " [  3   4   5 150  31  20   1]\n",
            " [ 18   9   2  10 158   6   1]\n",
            " [  6  10  11  16   2 148  34]\n",
            " [  2   2   2   0   0  34 160]]\n",
            "\n",
            "F1: 0.7486, Precision: 0.7486, Recall : 0.7486, Accuracy: 0.7486, Loss: 0.0784.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6Kth3CNII3t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMwq-cvgKn1w"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "SelfNet_mean_+_gelu_Youtube_Comments.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "80812c57c454a5cb47da895f264233db0a5d87621772a622276e795be9a4c20f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('python3.7': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
