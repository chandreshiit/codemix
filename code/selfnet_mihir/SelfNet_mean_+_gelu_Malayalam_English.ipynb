{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Malayalam English Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YagaAp_xTg6W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSSRsC1fNADr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muafgoq3zdah",
        "outputId": "cd656d64-7473-458b-a6ed-4d04a16d7ab9"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4B0ARAXTkLp"
      },
      "source": [
        "### Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzzoO4vmNW1V"
      },
      "outputs": [],
      "source": [
        "datapath = \"/home/ckm/ck_project/data/YouTubeComments/\"\n",
        "df_embedding = pd.read_csv(datapath+\"mal_eng_emb.bin\", sep=\" \", quoting=3, header=None, index_col=0,skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = map(float, tokens[1:])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: '\\x16O/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_7052/3021298826.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmal_eng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/ckm/ck_project/data/YouTubeComments/mal_eng_emb.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_7052/2199788894.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '\\x16O/'"
          ]
        }
      ],
      "source": [
        "mal_eng = load_vectors(\"/home/ckm/ck_project/data/YouTubeComments/mal_eng_emb.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "datapath = \"/home/ckm/ck_project/data/YouTubeComments/mal_eng_emb.bin\"\n",
        "\n",
        "ft = fasttext.load_model(datapath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2Wnirn_1ERuU",
        "outputId": "94f9f804-6f56-40c5-b8cb-6c083d841b70"
      },
      "outputs": [],
      "source": [
        "df_embedding.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJaOLL02TmUy"
      },
      "source": [
        "### Create vocab dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456blVxHEqJK",
        "outputId": "1fabfa5e-e9db-40dc-ab0d-d166d43011d8"
      },
      "outputs": [],
      "source": [
        "m = df_embedding.to_numpy()\n",
        "m.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKURV7-5NXfE",
        "outputId": "aa55221f-8b72-43cf-ead5-c93cc46fc391"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = df_embedding.to_numpy()\n",
        "\n",
        "vocab = []\n",
        "\n",
        "for word in list(df_embedding.index):\n",
        "  vocab.append(str(word))\n",
        "\n",
        "vocab_size , vocab_dim = embedding_matrix.shape\n",
        "vocab_size, vocab_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHZGs3aFF6b",
        "outputId": "a2d76acf-4109-40cb-f952-a38c12680201"
      },
      "outputs": [],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rju-5mvbVp6H"
      },
      "outputs": [],
      "source": [
        "word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY77Ru_NFMMs",
        "outputId": "45e84371-3f06-494c-dfb6-4ec87e2edd77"
      },
      "outputs": [],
      "source": [
        "len(word2idx) , len(idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBRDCquFF62W",
        "outputId": "ce912395-b2d0-479c-d114-549f630f681d"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "dict(itertools.islice(word2idx.items(), 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0HS8bPTqWq"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbzhx5a0m_Sr"
      },
      "outputs": [],
      "source": [
        "def sub_one(x):\n",
        "\treturn x - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSukKoeeNvSs",
        "outputId": "ac5d640e-fe25-4325-8fd9-cda5c59e06d6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/home/ckm/ck_project/data/YouTubeComments/Youtube_Comments_Data.csv')\n",
        "df= df.sample(frac = 1)\n",
        "\n",
        "df['Labels'] = df['Labels'].apply(sub_one)\n",
        "\n",
        "train_df = df[:6800]\n",
        "val_df = df[6800:8300]\n",
        "test_df = df[8300:]\n",
        "\n",
        "train_df.head()\n",
        "\n",
        "\n",
        "train_data =  train_df['commentText'].values\n",
        "train_labels = train_df['Labels'].values\n",
        "\n",
        "val_data =  val_df['commentText'].values\n",
        "val_labels = val_df['Labels'].values\n",
        "\n",
        "test_data =  test_df['commentText'].values\n",
        "test_labels = test_df['Labels'].values\n",
        "\n",
        "print(len(train_data), len(train_labels))\n",
        "print(len(val_data), len(val_labels))\n",
        "print(len(test_data), len(test_labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FMJNuKrDn-xb",
        "outputId": "0d136085-6d5e-44c5-c7ae-13f046263e35"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83AlL80DN1_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# post = pd.read_csv(\"positive_add1and2.csv\",sep=',')\n",
        "# neg = pd.read_csv(\"negative_add_1and2.csv\",sep=',')\n",
        "\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "# for index, row in post.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(1)\n",
        "\n",
        "\n",
        "# for index, row in neg.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(0)\n",
        "  \n",
        "\n",
        "# len(data), len(labels)\n",
        "\n",
        "# data, labels  = shuffle(data, labels, random_state = 40)\n",
        "\n",
        "# data[0], labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5iYXAJbTwJ8"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgF5Hb8weYwB"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "\n",
        "def tokenized_tensor(data):\n",
        "\n",
        "  output_tokenized = []\n",
        "\n",
        "  for sentence in data:\n",
        "    output = []\n",
        "    tokenized = tokenizer(sentence)\n",
        "    \n",
        "    for word in tokenized:\n",
        "      if word in word2idx:\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "      else:\n",
        "        word2idx[word] = len(word2idx)\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "\n",
        "    output = torch.tensor(output)\n",
        "\n",
        "\n",
        "    output_tokenized.append(output)\n",
        "\n",
        "  return output_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_pDpPLhiUPG"
      },
      "outputs": [],
      "source": [
        "# tokenized_sequences = tokenized_tensor(data)\n",
        "\n",
        "train_tokenized_sequences = tokenized_tensor(train_data)\n",
        "\n",
        "test_tokenized_seuqences = tokenized_tensor(test_data)\n",
        "\n",
        "val_tokenized_seuquences = tokenized_tensor(val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6WOxrifIFKQ",
        "outputId": "ef207cd4-55fc-456f-bc8e-adaadbe1cc96"
      },
      "outputs": [],
      "source": [
        "print(train_tokenized_sequences[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poFrSB5Opl1-",
        "outputId": "0bad193a-cf73-4f71-e6e9-509bfec95058"
      },
      "outputs": [],
      "source": [
        "word2idx['<PAD>'] = len(word2idx)\n",
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9AZYccLbVof",
        "outputId": "bf73d6d9-113b-4880-9a85-a27c29d13ae9"
      },
      "outputs": [],
      "source": [
        "len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYstutbgrABv"
      },
      "outputs": [],
      "source": [
        "## Create embedding matrix\n",
        "\n",
        "random_init = torch.nn.Parameter(torch.Tensor( (len(word2idx) - vocab_size), vocab_dim))\n",
        "torch.nn.init.kaiming_uniform_(random_init, a=math.sqrt(5))\n",
        "\n",
        "\n",
        "new_matrix = np.zeros( (len(word2idx), vocab_dim) )\n",
        "\n",
        "new_matrix[:vocab_size, :] = embedding_matrix\n",
        "\n",
        "embedding_matrix = new_matrix\n",
        "\n",
        "embedding_matrix[vocab_size:, :] = random_init.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0mL0x6J3KV",
        "outputId": "32d4bf4d-7ec2-4085-fce3-6c7b82f0922a"
      },
      "outputs": [],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cp0nnNdrazK"
      },
      "outputs": [],
      "source": [
        "# padded_sequences = pad_sequence(tokenized_sequences, batch_first= True, padding_value=107512)\n",
        "\n",
        "train_padded_sequences = pad_sequence(train_tokenized_sequences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "val_padded_sequences = pad_sequence(val_tokenized_seuquences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "test_padded_sequences = pad_sequence(test_tokenized_seuqences, batch_first= True, padding_value=word2idx['<PAD>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trl1D4QFII3e",
        "outputId": "281787e8-4bbd-4b9c-dea0-6f937b0b3f9a"
      },
      "outputs": [],
      "source": [
        "(train_padded_sequences[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSE4xlb2O8Ju"
      },
      "source": [
        "### Dataset and Data loader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISg-6szPOBr1"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
        "    \"\"\"\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.labels = labels\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        sequence = self.sequences[idx]\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        try:\n",
        "            sample[\"label\"] = label\n",
        "            sample[\"token\"] = sequence\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1LEy0ogII3g"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_padded_sequences, train_labels)\n",
        "\n",
        "val_dataset = Dataset(val_padded_sequences, val_labels)\n",
        "\n",
        "test_dataset = Dataset(test_padded_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQVUtYvII3g"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC2nFBOTynbR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENWuqJHeII3h"
      },
      "outputs": [],
      "source": [
        "## Hyper parameter\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "embed_dim = vocab_dim\n",
        "seq_len = 192\n",
        "hidden_size = 512\n",
        "num_layer = 3\n",
        "num_class = 7\n",
        "batch_size = 32\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 30\n",
        "CLIP = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2daJrk6PQb7"
      },
      "outputs": [],
      "source": [
        "# # Create datasets\n",
        "# dataset = Dataset(padded_sequences, labels)\n",
        "\n",
        "# split = 0.85\n",
        "# train_size = int(split*len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSYO1yrqPSgn"
      },
      "outputs": [],
      "source": [
        "\n",
        "## We call the dataloader class\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "## For testing\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "\n",
        "dataloaders = {'Train': train_loader, 'Val': val_loader}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ZYd39BII3i",
        "outputId": "3a10a91c-2116-4ada-e1f6-e3abc17ea147"
      },
      "outputs": [],
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoA6yF7iomTV",
        "outputId": "418e1523-d735-4082-f963-16580e8ea844"
      },
      "outputs": [],
      "source": [
        "max_len = -1\n",
        "for comment in val_dataset:\n",
        "  sentence = comment['token']\n",
        "  max_len = max(max_len,sentence.shape[0])\n",
        "\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0DXO4Q2II3i",
        "outputId": "471b3762-68ba-4ac6-8f4c-2acd20a5b427"
      },
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXQNerMvjIb"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR0tnE2NxphD"
      },
      "outputs": [],
      "source": [
        "class SelfMatchingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,  seq_length, embed_dim, **kwargs):\n",
        "\n",
        "      super(SelfMatchingLayer, self).__init__()\n",
        "\n",
        "      self.seq_length = seq_length\n",
        "      self.embed_dim  = embed_dim\n",
        "\n",
        "      self.P = torch.nn.Parameter(torch.Tensor(self.embed_dim, self.embed_dim))\n",
        "\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.P, a=math.sqrt(5))\n",
        "\n",
        "      \n",
        "    def forward(self, x):  \n",
        "      \n",
        "      # input shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "\n",
        "      #---------------------------------------------#\n",
        "      # calculate weight vector a = {e_i . P.Q . e_j}\n",
        "      #---------------------------------------------#\n",
        "\n",
        "      out = torch.matmul(x,  self.P)   #out shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "      out = torch.matmul(out, torch.transpose(x, 1, 2))   #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = F.gelu(out)         # apply non linear activation\n",
        "\n",
        "      #------------------------------------#\n",
        "      # take row wise mean and apply softmax\n",
        "      #------------------------------------#\n",
        "      out = torch.mean(out, 2)  #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = torch.softmax(out, 0)     #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = out.unsqueeze(1)          #out shape: [batch, 1, seq_len]\n",
        "\n",
        "      #-------------------------------------------#\n",
        "      # calculate weighted embedding of every word\n",
        "      #-------------------------------------------#\n",
        "      out = torch.matmul(out, x)\n",
        "\n",
        "      out = out.squeeze(1)\n",
        "\n",
        "      return out      #out shape: [batch, seq_len]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkC2PE1q3Fq",
        "outputId": "5188e8ce-3efa-4280-f761-511c46f26e2a"
      },
      "outputs": [],
      "source": [
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFAeZSyXu9KJ"
      },
      "outputs": [],
      "source": [
        "class SelfNet(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class):\n",
        "        super(SelfNet, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = word2idx['<PAD>'])\n",
        "        self.embedding.load_state_dict({'weight': torch.from_numpy(embedding_matrix)})\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        self.selfnet_layer = SelfMatchingLayer(seq_len, embed_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = num_layer, dropout = 0.3, bidirectional = True, batch_first = True )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2* hidden_size + embed_dim , hidden_size//4)\n",
        "        self.fc2 = nn.Linear(hidden_size//4, num_class)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        embedded = self.embedding(input)  #out shape = [batch, seq_len, embed_dim] \n",
        "\n",
        "        selfmatch_output = self.selfnet_layer(embedded)  #out shape = [batch, seq_len] \n",
        "\n",
        "        lstm_out, _ = self.lstm(embedded)     \n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]      #out shape = [batch, 2 * hidden_size]      \n",
        "\n",
        "        concat = torch.cat( (selfmatch_output, lstm_out), 1)     #out shape = [batch, 2 * hidden_size + seq_len ]      \n",
        "\n",
        "        linear_out = self.dropout(F.relu(self.fc1(concat)))     #out shape = [batch, hidden_size]      \n",
        "\n",
        "        final_out = self.fc2(linear_out)     #out shape = [batch, 2]      \n",
        "\n",
        "        return final_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Msc1-1zlOtAh"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Test\n",
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\n",
        "model = model.to(device)\n",
        "\n",
        "# for batch in train_loader:\n",
        "#   x = batch['token'].to(device)\n",
        "#   out = model(x)\n",
        "#   print(out.shape)\n",
        "#   break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-XvE3WHII3l",
        "outputId": "aaf727e6-066f-49bc-d07b-e32dfa27a9a0"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xjqPfmqx5Hj"
      },
      "source": [
        "### Optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifFhRpc2x4Fv"
      },
      "outputs": [],
      "source": [
        "#optimizer\n",
        "optimizer = Adam(model.parameters(), lr = LEARNING_RATE, eps=1e-8)\n",
        "#Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04ozLaUUx-eo"
      },
      "outputs": [],
      "source": [
        "#to calculate accuracy\n",
        "\n",
        "def get_accuracy(preds, labels):\n",
        "  total_acc = 0.0\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    if labels[i] == preds[i]:\n",
        "      total_acc+=1.0\n",
        "  \n",
        "  return total_acc / len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D33SEPjzILZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP5of6JbII3n",
        "outputId": "58296fc2-81e5-4394-eec6-d979870d53b0"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5, verbose = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o0-BUMKII3o"
      },
      "outputs": [],
      "source": [
        "PATH = '/home/ckm/ck_project/codemix/code/selfnet_mihir/models/selfnet_mean+gelu_2_mihir_yt_1.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZkPq1t6yBwx",
        "outputId": "4a678302-dc2f-421d-a886-c7448087ca26"
      },
      "outputs": [],
      "source": [
        "best_valid_f1 = 0.0000\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "  \n",
        "\n",
        "    print('-'*50)\n",
        "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
        "\n",
        "    for phase in ['Train', 'Val']:\n",
        "\n",
        "        loss = 0.0   #epoch loss\n",
        "        accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        if phase == 'Train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        \n",
        "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
        "\n",
        "          for batch in tepoch:\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            text = batch[\"token\"].to(device)\n",
        "            \n",
        "\n",
        "            output = model(text)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            if phase == 'Train':\n",
        "\n",
        "                #zero gradients\n",
        "                optimizer.zero_grad() \n",
        "\n",
        "                # Backward pass  (calculates the gradients)\n",
        "                loss.backward()   \n",
        "\n",
        "                # gradient clipping\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
        "\n",
        "                optimizer.step()             # Updates the weights    \n",
        "\n",
        "            sleep(0.1)\n",
        "            _, preds = output.data.max(1)\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "            \n",
        "            batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "            \n",
        "            \n",
        "            loss += loss.item()\n",
        "            accuracy+= batch_acc\n",
        "\n",
        "              \n",
        "          epoch_loss = loss / (len(dataloaders[phase]))\n",
        "          epoch_acc = accuracy / (len(dataloaders[phase]))\n",
        "\n",
        "          print(phase + \":\")\n",
        "          \n",
        "          \n",
        "          #print(confusion_matrix(y_true, y_pred))\n",
        "          pre = precision_score(y_true, y_pred, average='weighted')\n",
        "          recall = recall_score(y_true, y_pred, average='weighted')\n",
        "          f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "          \n",
        "\n",
        "          print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))\n",
        "          # save best model\n",
        "          print()\n",
        "          \n",
        "            \n",
        "          if phase == 'Val':\n",
        "                \n",
        "                if f1 > best_valid_f1:\n",
        "                    best_valid_f1 = f1\n",
        "                    \n",
        "                    torch.save(model.state_dict(), PATH)\n",
        "                    print('Model Saved!')\n",
        "                    \n",
        "                scheduler.step()\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yJchRvUz2nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsq5MiaHII3r"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L66ZUsoII3r"
      },
      "outputs": [],
      "source": [
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EceKQVWTII3r"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1DB4Su5II3r"
      },
      "outputs": [],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X99rC-LvII3s"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQwRQc_NII3s"
      },
      "outputs": [],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQs04_VAII3t"
      },
      "outputs": [],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6Kth3CNII3t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMwq-cvgKn1w"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "SelfNet_mean_+_gelu_Youtube_Comments.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "80812c57c454a5cb47da895f264233db0a5d87621772a622276e795be9a4c20f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('python3.7': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
