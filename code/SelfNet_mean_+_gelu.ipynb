{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YagaAp_xTg6W"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PSSRsC1fNADr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Muafgoq3zdah"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4B0ARAXTkLp"
   },
   "source": [
    "### Load embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HzzoO4vmNW1V"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_embedding = pd.read_csv('hing_emb (1)', sep=\" \", quoting=3, header=None, index_col=0,skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJaOLL02TmUy"
   },
   "source": [
    "### Create vocab dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKURV7-5NXfE",
    "outputId": "1dd60138-77c9-4d44-adac-1a551117b687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44050, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = df_embedding.to_numpy()\n",
    "\n",
    "vocab = []\n",
    "\n",
    "for word in list(df_embedding.index):\n",
    "  vocab.append(str(word))\n",
    "\n",
    "vocab_size , vocab_dim = embedding_matrix.shape\n",
    "vocab_size, vocab_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Rju-5mvbVp6H"
   },
   "outputs": [],
   "source": [
    "word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "He0HS8bPTqWq"
   },
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aSukKoeeNvSs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115000, 115000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "val_df = pd.read_csv(\"valid.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "train_data =  train_df['tweets'].values\n",
    "train_labels = train_df['labels'].values\n",
    "\n",
    "val_data =  val_df['tweets'].values\n",
    "val_labels = val_df['labels'].values\n",
    "\n",
    "test_data =  test_df['tweets'].values\n",
    "test_labels = test_df['labels'].values\n",
    "\n",
    "len(train_data), len(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83AlL80DN1_5",
    "outputId": "3b88ae76-1153-499e-ea6b-f57c00ccb957"
   },
   "outputs": [],
   "source": [
    "\n",
    "# post = pd.read_csv(\"positive_add1and2.csv\",sep=',')\n",
    "# neg = pd.read_csv(\"negative_add_1and2.csv\",sep=',')\n",
    "\n",
    "# data = []\n",
    "# labels = []\n",
    "\n",
    "# for index, row in post.iterrows():\n",
    "#   if index >= 30000:\n",
    "#     break\n",
    "  \n",
    "#   comment = str(row['tweet'])\n",
    "#   data.append(comment)\n",
    "#   labels.append(1)\n",
    "\n",
    "\n",
    "# for index, row in neg.iterrows():\n",
    "#   if index >= 30000:\n",
    "#     break\n",
    "  \n",
    "#   comment = str(row['tweet'])\n",
    "#   data.append(comment)\n",
    "#   labels.append(0)\n",
    "  \n",
    "\n",
    "# len(data), len(labels)\n",
    "\n",
    "# data, labels  = shuffle(data, labels, random_state = 40)\n",
    "\n",
    "# data[0], labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5iYXAJbTwJ8"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QgF5Hb8weYwB"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "\n",
    "def tokenized_tensor(data):\n",
    "\n",
    "  output_tokenized = []\n",
    "\n",
    "  for sentence in data:\n",
    "    output = []\n",
    "    tokenized = tokenizer(sentence)\n",
    "    \n",
    "    for word in tokenized:\n",
    "      if word in word2idx:\n",
    "        id = word2idx[word]\n",
    "        output.append(id)\n",
    "      else:\n",
    "        word2idx[word] = len(word2idx)\n",
    "        id = word2idx[word]\n",
    "        output.append(id)\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "\n",
    "\n",
    "    output_tokenized.append(output)\n",
    "\n",
    "  return output_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K_pDpPLhiUPG"
   },
   "outputs": [],
   "source": [
    "# tokenized_sequences = tokenized_tensor(data)\n",
    "\n",
    "train_tokenized_sequences = tokenized_tensor(train_data)\n",
    "\n",
    "test_tokenized_seuqences = tokenized_tensor(test_data)\n",
    "\n",
    "val_tokenized_seuquences = tokenized_tensor(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poFrSB5Opl1-",
    "outputId": "8abe6aa5-afdf-4447-a22e-ad4d46b49c72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172527"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['<PAD>'] = len(word2idx)\n",
    "word2idx['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9AZYccLbVof",
    "outputId": "8a7d952d-de4c-4ec0-92a6-b9c835ea3d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GYstutbgrABv"
   },
   "outputs": [],
   "source": [
    "## Create embedding matrix\n",
    "\n",
    "random_init = torch.nn.Parameter(torch.Tensor( (len(word2idx) - vocab_size), vocab_dim))\n",
    "torch.nn.init.kaiming_uniform_(random_init, a=math.sqrt(5))\n",
    "\n",
    "\n",
    "new_matrix = np.zeros( (len(word2idx), vocab_dim) )\n",
    "\n",
    "new_matrix[:vocab_size, :] = embedding_matrix\n",
    "\n",
    "embedding_matrix = new_matrix\n",
    "\n",
    "embedding_matrix[vocab_size:, :] = random_init.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3cp0nnNdrazK"
   },
   "outputs": [],
   "source": [
    "# padded_sequences = pad_sequence(tokenized_sequences, batch_first= True, padding_value=107512)\n",
    "\n",
    "train_padded_sequences = pad_sequence(train_tokenized_sequences, batch_first= True, padding_value=172527)\n",
    "\n",
    "val_padded_sequences = pad_sequence(val_tokenized_seuquences, batch_first= True, padding_value=172527)\n",
    "\n",
    "test_padded_sequences = pad_sequence(test_tokenized_seuqences, batch_first= True, padding_value=172527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_padded_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSE4xlb2O8Ju"
   },
   "source": [
    "### Dataset and Data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ISg-6szPOBr1"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.labels = labels\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        sequence = self.sequences[idx]\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "\n",
    "        try:\n",
    "            sample[\"label\"] = label\n",
    "            sample[\"token\"] = sequence\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_padded_sequences, train_labels)\n",
    "\n",
    "val_dataset = Dataset(val_padded_sequences, val_labels)\n",
    "\n",
    "test_dataset = Dataset(test_padded_sequences, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameter\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "embed_dim = vocab_dim\n",
    "seq_len = 65\n",
    "hidden_size = 512\n",
    "num_layer = 3\n",
    "num_class = 2\n",
    "batch_size = 256\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 30\n",
    "CLIP = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "R2daJrk6PQb7"
   },
   "outputs": [],
   "source": [
    "# # Create datasets\n",
    "# dataset = Dataset(padded_sequences, labels)\n",
    "\n",
    "# split = 0.85\n",
    "# train_size = int(split*len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LSYO1yrqPSgn"
   },
   "outputs": [],
   "source": [
    "\n",
    "## We call the dataloader class\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "## For testing\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "\n",
    "dataloaders = {'Train': train_loader, 'Val': val_loader}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 83, 117)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'token': tensor([ 23066,  23067,  22357,  29756,  21000,  21010,  23068,  21018,  23069,\n",
       "          21000,  21000,  20996,  21182, 172527, 172527, 172527, 172527, 172527,\n",
       "         172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527,\n",
       "         172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527,\n",
       "         172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527,\n",
       "         172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527,\n",
       "         172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527, 172527,\n",
       "         172527, 172527])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDXQNerMvjIb"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "wR0tnE2NxphD"
   },
   "outputs": [],
   "source": [
    "class SelfMatchingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self,  seq_length, embed_dim, **kwargs):\n",
    "\n",
    "      super(SelfMatchingLayer, self).__init__()\n",
    "\n",
    "      self.seq_length = seq_length\n",
    "      self.embed_dim  = embed_dim\n",
    "\n",
    "      self.P = torch.nn.Parameter(torch.Tensor(self.embed_dim, self.embed_dim))\n",
    "\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.P, a=math.sqrt(5))\n",
    "\n",
    "      \n",
    "    def forward(self, x):  \n",
    "      \n",
    "      # input shape: [batch, seq_len, embed_dim]\n",
    "\n",
    "\n",
    "      #---------------------------------------------#\n",
    "      # calculate weight vector a = {e_i . P.Q . e_j}\n",
    "      #---------------------------------------------#\n",
    "\n",
    "      out = torch.matmul(x,  self.P)   #out shape: [batch, seq_len, embed_dim]\n",
    "\n",
    "      out = torch.matmul(out, torch.transpose(x, 1, 2))   #out shape: [batch, seq_len, seq_len]\n",
    "\n",
    "      out = F.gelu(out)         # apply non linear activation\n",
    "\n",
    "      #------------------------------------#\n",
    "      # take row wise mean and apply softmax\n",
    "      #------------------------------------#\n",
    "      out = torch.mean(out, 2)  #out shape: [batch, seq_len, seq_len]\n",
    "\n",
    "      out = torch.softmax(out, 0)     #out shape: [batch, seq_len, seq_len]\n",
    "\n",
    "      out = out.unsqueeze(1)          #out shape: [batch, 1, seq_len]\n",
    "\n",
    "      #-------------------------------------------#\n",
    "      # calculate weighted embedding of every word\n",
    "      #-------------------------------------------#\n",
    "      out = torch.matmul(out, x)\n",
    "\n",
    "      out = out.squeeze(1)\n",
    "\n",
    "      return out      #out shape: [batch, seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "LFAeZSyXu9KJ"
   },
   "outputs": [],
   "source": [
    "class SelfNet(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class):\n",
    "        super(SelfNet, self).__init__()\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = word2idx['<PAD>'])\n",
    "        self.embedding.load_state_dict({'weight': torch.from_numpy(embedding_matrix)})\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "        self.selfnet_layer = SelfMatchingLayer(seq_len, embed_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = num_layer, dropout = 0.3, bidirectional = True, batch_first = True )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(2* hidden_size + embed_dim , hidden_size//4)\n",
    "        self.fc2 = nn.Linear(hidden_size//4, num_class)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        embedded = self.embedding(input)  #out shape = [batch, seq_len, embed_dim] \n",
    "\n",
    "        selfmatch_output = self.selfnet_layer(embedded)  #out shape = [batch, seq_len] \n",
    "\n",
    "        lstm_out, _ = self.lstm(embedded)     \n",
    "\n",
    "        lstm_out = lstm_out[:, -1, :]      #out shape = [batch, 2 * hidden_size]      \n",
    "\n",
    "        concat = torch.cat( (selfmatch_output, lstm_out), 1)     #out shape = [batch, 2 * hidden_size + seq_len ]      \n",
    "\n",
    "        linear_out = self.dropout(F.relu(self.fc1(concat)))     #out shape = [batch, hidden_size]      \n",
    "\n",
    "        final_out = self.fc2(linear_out)     #out shape = [batch, 2]      \n",
    "\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Msc1-1zlOtAh"
   },
   "outputs": [],
   "source": [
    "\n",
    "### Test\n",
    "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\n",
    "model = model.to(device)\n",
    "\n",
    "# for batch in train_loader:\n",
    "#   x = batch['token'].to(device)\n",
    "#   out = model(x)\n",
    "#   print(out.shape)\n",
    "#   break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfNet(\n",
       "  (embedding): Embedding(172528, 100, padding_idx=172527)\n",
       "  (selfnet_layer): SelfMatchingLayer()\n",
       "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xjqPfmqx5Hj"
   },
   "source": [
    "### Optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ifFhRpc2x4Fv"
   },
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = Adam(model.parameters(), lr = LEARNING_RATE, eps=1e-8)\n",
    "#Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "04ozLaUUx-eo"
   },
   "outputs": [],
   "source": [
    "#to calculate accuracy\n",
    "\n",
    "def get_accuracy(preds, labels):\n",
    "  total_acc = 0.0\n",
    "  \n",
    "  for i in range(len(labels)):\n",
    "    if labels[i] == preds[i]:\n",
    "      total_acc+=1.0\n",
    "  \n",
    "  return total_acc / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D33SEPjzILZ"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c55f461717bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/best_selfnet_mean+gelu_2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZkPq1t6yBwx",
    "outputId": "5a07c57b-6e79-4ca2-ee32-93ab491f326d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.7914, Precision: 0.7937, Recall : 0.7918, Accuracy: 0.7918, Loss: 0.0017.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8589, Precision: 0.8598, Recall : 0.8590, Accuracy: 0.8590, Loss: 0.0091.\n",
      "\n",
      "Model Saved!\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.8692, Precision: 0.8703, Recall : 0.8693, Accuracy: 0.8693, Loss: 0.0016.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8708, Precision: 0.8724, Recall : 0.8709, Accuracy: 0.8709, Loss: 0.0071.\n",
      "\n",
      "Model Saved!\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.8869, Precision: 0.8874, Recall : 0.8869, Accuracy: 0.8869, Loss: 0.0015.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8731, Precision: 0.8737, Recall : 0.8732, Accuracy: 0.8732, Loss: 0.0075.\n",
      "\n",
      "Model Saved!\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:01<00:00,  3.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9011, Precision: 0.9015, Recall : 0.9011, Accuracy: 0.9011, Loss: 0.0010.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8729, Precision: 0.8746, Recall : 0.8730, Accuracy: 0.8730, Loss: 0.0082.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9148, Precision: 0.9150, Recall : 0.9148, Accuracy: 0.9148, Loss: 0.0008.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8664, Precision: 0.8664, Recall : 0.8664, Accuracy: 0.8664, Loss: 0.0096.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9278, Precision: 0.9281, Recall : 0.9278, Accuracy: 0.9278, Loss: 0.0008.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8669, Precision: 0.8687, Recall : 0.8671, Accuracy: 0.8671, Loss: 0.0087.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9388, Precision: 0.9390, Recall : 0.9388, Accuracy: 0.9388, Loss: 0.0009.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8650, Precision: 0.8674, Recall : 0.8652, Accuracy: 0.8652, Loss: 0.0074.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9454, Precision: 0.9455, Recall : 0.9454, Accuracy: 0.9454, Loss: 0.0007.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8578, Precision: 0.8579, Recall : 0.8578, Accuracy: 0.8578, Loss: 0.0108.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9513, Precision: 0.9514, Recall : 0.9513, Accuracy: 0.9513, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8558, Precision: 0.8572, Recall : 0.8559, Accuracy: 0.8559, Loss: 0.0100.\n",
      "\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-04.\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9608, Precision: 0.9608, Recall : 0.9608, Accuracy: 0.9608, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8561, Precision: 0.8569, Recall : 0.8562, Accuracy: 0.8562, Loss: 0.0129.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9622, Precision: 0.9623, Recall : 0.9622, Accuracy: 0.9622, Loss: 0.0006.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8519, Precision: 0.8528, Recall : 0.8519, Accuracy: 0.8519, Loss: 0.0141.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9639, Precision: 0.9639, Recall : 0.9639, Accuracy: 0.9639, Loss: 0.0002.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8505, Precision: 0.8515, Recall : 0.8506, Accuracy: 0.8506, Loss: 0.0166.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9654, Precision: 0.9654, Recall : 0.9654, Accuracy: 0.9654, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8481, Precision: 0.8483, Recall : 0.8481, Accuracy: 0.8481, Loss: 0.0094.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9669, Precision: 0.9669, Recall : 0.9669, Accuracy: 0.9669, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8490, Precision: 0.8506, Recall : 0.8491, Accuracy: 0.8491, Loss: 0.0160.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9679, Precision: 0.9679, Recall : 0.9679, Accuracy: 0.9679, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8476, Precision: 0.8484, Recall : 0.8477, Accuracy: 0.8477, Loss: 0.0156.\n",
      "\n",
      "Epoch    15: reducing learning rate of group 0 to 4.0000e-05.\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9698, Precision: 0.9699, Recall : 0.9698, Accuracy: 0.9698, Loss: 0.0004.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8460, Precision: 0.8468, Recall : 0.8461, Accuracy: 0.8461, Loss: 0.0159.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9696, Precision: 0.9696, Recall : 0.9696, Accuracy: 0.9696, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8450, Precision: 0.8457, Recall : 0.8451, Accuracy: 0.8451, Loss: 0.0136.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9697, Precision: 0.9697, Recall : 0.9697, Accuracy: 0.9697, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8462, Precision: 0.8469, Recall : 0.8463, Accuracy: 0.8463, Loss: 0.0268.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9706, Precision: 0.9706, Recall : 0.9706, Accuracy: 0.9706, Loss: 0.0004.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8453, Precision: 0.8459, Recall : 0.8454, Accuracy: 0.8454, Loss: 0.0117.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9704, Precision: 0.9704, Recall : 0.9704, Accuracy: 0.9704, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8438, Precision: 0.8441, Recall : 0.8438, Accuracy: 0.8438, Loss: 0.0174.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9703, Precision: 0.9703, Recall : 0.9703, Accuracy: 0.9703, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8463, Precision: 0.8472, Recall : 0.8463, Accuracy: 0.8463, Loss: 0.0179.\n",
      "\n",
      "Epoch    21: reducing learning rate of group 0 to 8.0000e-06.\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9710, Precision: 0.9711, Recall : 0.9710, Accuracy: 0.9710, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8453, Precision: 0.8460, Recall : 0.8454, Accuracy: 0.8454, Loss: 0.0162.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9709, Precision: 0.9709, Recall : 0.9709, Accuracy: 0.9709, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8456, Precision: 0.8464, Recall : 0.8457, Accuracy: 0.8457, Loss: 0.0194.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:02<00:00,  3.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9710, Precision: 0.9711, Recall : 0.9710, Accuracy: 0.9710, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8457, Precision: 0.8464, Recall : 0.8458, Accuracy: 0.8458, Loss: 0.0176.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9712, Precision: 0.9712, Recall : 0.9712, Accuracy: 0.9712, Loss: 0.0004.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8445, Precision: 0.8452, Recall : 0.8446, Accuracy: 0.8446, Loss: 0.0150.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9712, Precision: 0.9712, Recall : 0.9712, Accuracy: 0.9712, Loss: 0.0003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8458, Precision: 0.8466, Recall : 0.8459, Accuracy: 0.8459, Loss: 0.0212.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9707, Precision: 0.9707, Recall : 0.9707, Accuracy: 0.9707, Loss: 0.0004.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8440, Precision: 0.8446, Recall : 0.8440, Accuracy: 0.8440, Loss: 0.0161.\n",
      "\n",
      "Epoch    27: reducing learning rate of group 0 to 1.6000e-06.\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9712, Precision: 0.9712, Recall : 0.9712, Accuracy: 0.9712, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8442, Precision: 0.8450, Recall : 0.8443, Accuracy: 0.8443, Loss: 0.0151.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9711, Precision: 0.9711, Recall : 0.9711, Accuracy: 0.9711, Loss: 0.0004.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8447, Precision: 0.8455, Recall : 0.8448, Accuracy: 0.8448, Loss: 0.0134.\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [02:03<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "F1: 0.9710, Precision: 0.9710, Recall : 0.9710, Accuracy: 0.9710, Loss: 0.0005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:10<00:00,  8.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "F1: 0.8442, Precision: 0.8449, Recall : 0.8443, Accuracy: 0.8443, Loss: 0.0108.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_f1 = 0.0000\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "  \n",
    "\n",
    "    print('-'*50)\n",
    "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
    "\n",
    "    for phase in ['Train', 'Val']:\n",
    "\n",
    "        loss = 0.0   #epoch loss\n",
    "        accuracy = 0.0   #epoch accuracy\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        if phase == 'Train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "\n",
    "          for batch in tepoch:\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            text = batch[\"token\"].to(device)\n",
    "\n",
    "            output = model(text)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            if phase == 'Train':\n",
    "\n",
    "                #zero gradients\n",
    "                optimizer.zero_grad() \n",
    "\n",
    "                # Backward pass  (calculates the gradients)\n",
    "                loss.backward()   \n",
    "\n",
    "                # gradient clipping\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
    "\n",
    "                optimizer.step()             # Updates the weights    \n",
    "\n",
    "            sleep(0.1)\n",
    "            _, preds = output.data.max(1)\n",
    "            y_pred.extend(preds.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "            \n",
    "            batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
    "            \n",
    "            \n",
    "            loss += loss.item()\n",
    "            accuracy+= batch_acc\n",
    "\n",
    "              \n",
    "          epoch_loss = loss / (len(dataloaders[phase]))\n",
    "          epoch_acc = accuracy / (len(dataloaders[phase]))\n",
    "\n",
    "          print(phase + \":\")\n",
    "          \n",
    "          \n",
    "          #print(confusion_matrix(y_true, y_pred))\n",
    "          pre = precision_score(y_true, y_pred, average='weighted')\n",
    "          recall = recall_score(y_true, y_pred, average='weighted')\n",
    "          f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "          \n",
    "\n",
    "          print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))\n",
    "          # save best model\n",
    "          print()\n",
    "          \n",
    "            \n",
    "          if phase == 'Val':\n",
    "                \n",
    "                if f1 > best_valid_f1:\n",
    "                    best_valid_f1 = f1\n",
    "                    \n",
    "                    torch.save(model.state_dict(), PATH)\n",
    "                    print('Model Saved!')\n",
    "                    \n",
    "                scheduler.step(f1)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yJchRvUz2nf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.0   #epoch loss\n",
    "accuracy = 0.0   #epoch accuracy\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# set the model to evaluation mode            \n",
    "model.eval()\n",
    "        \n",
    "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "  for batch in tepoch:\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    text = batch[\"token\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(text)\n",
    "    \n",
    "    \n",
    "    _, preds = output.data.max(1)\n",
    "    y_pred.extend(preds.tolist())\n",
    "    y_true.extend(labels.tolist())\n",
    "            \n",
    "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
    "\n",
    "    loss = criterion(output, labels)\n",
    "            \n",
    "            \n",
    "    loss += loss.item()\n",
    "    accuracy+= batch_acc\n",
    "\n",
    "    sleep(0.1)\n",
    "\n",
    "              \n",
    "epoch_loss = loss / (len(val_loader))\n",
    "epoch_acc = accuracy / (len(val_loader))\n",
    "print('')\n",
    "print(\"Inference:\")\n",
    "print(\"\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "pre = precision_score(y_true, y_pred, average='micro')\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print(\"\")\n",
    "\n",
    "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SelfNet:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l2\", \"lstm.weight_hh_l2\", \"lstm.bias_ih_l2\", \"lstm.bias_hh_l2\", \"lstm.weight_ih_l2_reverse\", \"lstm.weight_hh_l2_reverse\", \"lstm.bias_ih_l2_reverse\", \"lstm.bias_hh_l2_reverse\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 100]) from checkpoint, the shape in current model is torch.Size([2048, 100]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([1024, 100]) from checkpoint, the shape in current model is torch.Size([2048, 100]).\n\tsize mismatch for lstm.weight_hh_l0_reverse: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l0_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l0_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.weight_ih_l1_reverse: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for lstm.weight_hh_l1_reverse: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l1_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l1_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([256, 612]) from checkpoint, the shape in current model is torch.Size([512, 1124]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([2, 256]) from checkpoint, the shape in current model is torch.Size([2, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-fe610092ef9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/best_selfnet_mean+gelu.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SelfNet:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l2\", \"lstm.weight_hh_l2\", \"lstm.bias_ih_l2\", \"lstm.bias_hh_l2\", \"lstm.weight_ih_l2_reverse\", \"lstm.weight_hh_l2_reverse\", \"lstm.bias_ih_l2_reverse\", \"lstm.bias_hh_l2_reverse\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 100]) from checkpoint, the shape in current model is torch.Size([2048, 100]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([1024, 100]) from checkpoint, the shape in current model is torch.Size([2048, 100]).\n\tsize mismatch for lstm.weight_hh_l0_reverse: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l0_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l0_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.weight_ih_l1_reverse: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for lstm.weight_hh_l1_reverse: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for lstm.bias_ih_l1_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for lstm.bias_hh_l1_reverse: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([256, 612]) from checkpoint, the shape in current model is torch.Size([512, 1124]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([2, 256]) from checkpoint, the shape in current model is torch.Size([2, 512])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/best_selfnet_mean+gelu.pt'))\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.0   #epoch loss\n",
    "accuracy = 0.0   #epoch accuracy\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# set the model to evaluation mode            \n",
    "model.eval()\n",
    "        \n",
    "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "  for batch in tepoch:\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    text = batch[\"token\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(text)\n",
    "    \n",
    "    \n",
    "    _, preds = output.data.max(1)\n",
    "    y_pred.extend(preds.tolist())\n",
    "    y_true.extend(labels.tolist())\n",
    "            \n",
    "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
    "\n",
    "    loss = criterion(output, labels)\n",
    "            \n",
    "            \n",
    "    loss += loss.item()\n",
    "    accuracy+= batch_acc\n",
    "\n",
    "    sleep(0.1)\n",
    "\n",
    "              \n",
    "epoch_loss = loss / (len(val_loader))\n",
    "epoch_acc = accuracy / (len(val_loader))\n",
    "print('')\n",
    "print(\"Inference:\")\n",
    "print(\"\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "pre = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(\"\")\n",
    "\n",
    "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.0   #epoch loss\n",
    "accuracy = 0.0   #epoch accuracy\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# set the model to evaluation mode            \n",
    "model.eval()\n",
    "        \n",
    "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "  for batch in tepoch:\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    text = batch[\"token\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(text)\n",
    "    \n",
    "    \n",
    "    _, preds = output.data.max(1)\n",
    "    y_pred.extend(preds.tolist())\n",
    "    y_true.extend(labels.tolist())\n",
    "            \n",
    "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
    "\n",
    "    loss = criterion(output, labels)\n",
    "            \n",
    "            \n",
    "    loss += loss.item()\n",
    "    accuracy+= batch_acc\n",
    "\n",
    "    sleep(0.1)\n",
    "\n",
    "              \n",
    "epoch_loss = loss / (len(val_loader))\n",
    "epoch_acc = accuracy / (len(val_loader))\n",
    "print('')\n",
    "print(\"Inference:\")\n",
    "print(\"\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "pre = precision_score(y_true, y_pred, average='micro')\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print(\"\")\n",
    "\n",
    "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SelfNet - mean + gelu.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
