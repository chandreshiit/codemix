{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "YouTube Comments dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YagaAp_xTg6W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /home/ckm/python3.7/lib/python3.7/site-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (2.26.0)\n",
            "Requirement already satisfied: torch==1.10.0 in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (1.10.0)\n",
            "Requirement already satisfied: numpy in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /home/ckm/python3.7/lib/python3.7/site-packages (from torchtext) (4.62.2)\n",
            "Requirement already satisfied: typing-extensions in /home/ckm/python3.7/lib/python3.7/site-packages (from torch==1.10.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ckm/python3.7/lib/python3.7/site-packages (from requests->torchtext) (3.2)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/home/ckm/python3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PSSRsC1fNADr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muafgoq3zdah",
        "outputId": "cd656d64-7473-458b-a6ed-4d04a16d7ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Dec 27 15:10:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-PCIE...  Off  | 00000000:17:00.0 Off |                    0 |\n",
            "| N/A   79C    P0    74W / 250W |  11446MiB / 16160MiB |     79%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      9726      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    0   N/A  N/A     13422      C   .../ckm/python3.7/bin/python     4071MiB |\n",
            "|    0   N/A  N/A     30438      C   ./darknet                        7367MiB |\n",
            "+-----------------------------------------------------------------------------+\n",
            "WARNING: infoROM is corrupted at gpu 0000:17:00.0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4B0ARAXTkLp"
      },
      "source": [
        "### Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "HzzoO4vmNW1V"
      },
      "outputs": [],
      "source": [
        "datapath = \"/home/ckm/ck_project/codemix/code/selfnet_mihir/\"\n",
        "df_embedding = pd.read_csv(datapath+'hing_emb', sep=\" \", quoting=3, header=None, index_col=0,skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2Wnirn_1ERuU",
        "outputId": "94f9f804-6f56-40c5-b8cb-6c083d841b70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nahi</th>\n",
              "      <td>-0.079912</td>\n",
              "      <td>0.522077</td>\n",
              "      <td>0.009111</td>\n",
              "      <td>-0.103475</td>\n",
              "      <td>-0.042439</td>\n",
              "      <td>0.229031</td>\n",
              "      <td>0.360524</td>\n",
              "      <td>0.047913</td>\n",
              "      <td>0.129397</td>\n",
              "      <td>0.184819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049488</td>\n",
              "      <td>-0.291750</td>\n",
              "      <td>0.188353</td>\n",
              "      <td>-0.099099</td>\n",
              "      <td>0.271938</td>\n",
              "      <td>0.311072</td>\n",
              "      <td>-0.446256</td>\n",
              "      <td>-0.093532</td>\n",
              "      <td>0.118786</td>\n",
              "      <td>-0.221102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.268486</td>\n",
              "      <td>0.454443</td>\n",
              "      <td>-0.211620</td>\n",
              "      <td>-0.029896</td>\n",
              "      <td>-0.123828</td>\n",
              "      <td>0.119760</td>\n",
              "      <td>0.146776</td>\n",
              "      <td>0.152356</td>\n",
              "      <td>0.136670</td>\n",
              "      <td>-0.086144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.256750</td>\n",
              "      <td>0.170485</td>\n",
              "      <td>-0.081619</td>\n",
              "      <td>-0.110159</td>\n",
              "      <td>-0.012980</td>\n",
              "      <td>0.211806</td>\n",
              "      <td>-0.197437</td>\n",
              "      <td>0.094797</td>\n",
              "      <td>-0.070250</td>\n",
              "      <td>-0.186570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ki</th>\n",
              "      <td>-0.342798</td>\n",
              "      <td>0.568509</td>\n",
              "      <td>0.049298</td>\n",
              "      <td>-0.111945</td>\n",
              "      <td>-0.312412</td>\n",
              "      <td>0.490620</td>\n",
              "      <td>0.442846</td>\n",
              "      <td>0.053863</td>\n",
              "      <td>0.177461</td>\n",
              "      <td>0.111002</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491238</td>\n",
              "      <td>-0.074531</td>\n",
              "      <td>0.165319</td>\n",
              "      <td>-0.015633</td>\n",
              "      <td>0.151389</td>\n",
              "      <td>0.332968</td>\n",
              "      <td>-0.311262</td>\n",
              "      <td>0.057184</td>\n",
              "      <td>-0.281329</td>\n",
              "      <td>-0.346765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ke</th>\n",
              "      <td>-0.299528</td>\n",
              "      <td>0.510413</td>\n",
              "      <td>-0.033908</td>\n",
              "      <td>-0.064933</td>\n",
              "      <td>-0.439092</td>\n",
              "      <td>0.359395</td>\n",
              "      <td>0.342511</td>\n",
              "      <td>-0.102557</td>\n",
              "      <td>0.354761</td>\n",
              "      <td>0.632507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202599</td>\n",
              "      <td>-0.206487</td>\n",
              "      <td>0.178269</td>\n",
              "      <td>-0.108783</td>\n",
              "      <td>0.322591</td>\n",
              "      <td>0.347032</td>\n",
              "      <td>-0.558663</td>\n",
              "      <td>-0.018923</td>\n",
              "      <td>0.116121</td>\n",
              "      <td>-0.325165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>se</th>\n",
              "      <td>-0.435697</td>\n",
              "      <td>0.357603</td>\n",
              "      <td>-0.040995</td>\n",
              "      <td>0.107330</td>\n",
              "      <td>-0.313671</td>\n",
              "      <td>0.268082</td>\n",
              "      <td>0.246396</td>\n",
              "      <td>0.005616</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>0.249072</td>\n",
              "      <td>...</td>\n",
              "      <td>0.409665</td>\n",
              "      <td>-0.106801</td>\n",
              "      <td>-0.285788</td>\n",
              "      <td>0.028810</td>\n",
              "      <td>0.064475</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>-0.666445</td>\n",
              "      <td>-0.167434</td>\n",
              "      <td>-0.310887</td>\n",
              "      <td>-0.367422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           1         2         3         4         5         6         7    \\\n",
              "0                                                                            \n",
              "nahi -0.079912  0.522077  0.009111 -0.103475 -0.042439  0.229031  0.360524   \n",
              "to    0.268486  0.454443 -0.211620 -0.029896 -0.123828  0.119760  0.146776   \n",
              "ki   -0.342798  0.568509  0.049298 -0.111945 -0.312412  0.490620  0.442846   \n",
              "ke   -0.299528  0.510413 -0.033908 -0.064933 -0.439092  0.359395  0.342511   \n",
              "se   -0.435697  0.357603 -0.040995  0.107330 -0.313671  0.268082  0.246396   \n",
              "\n",
              "           8         9         10   ...       91        92        93   \\\n",
              "0                                   ...                                 \n",
              "nahi  0.047913  0.129397  0.184819  ...  0.049488 -0.291750  0.188353   \n",
              "to    0.152356  0.136670 -0.086144  ...  0.256750  0.170485 -0.081619   \n",
              "ki    0.053863  0.177461  0.111002  ...  0.491238 -0.074531  0.165319   \n",
              "ke   -0.102557  0.354761  0.632507  ...  0.202599 -0.206487  0.178269   \n",
              "se    0.005616  0.089185  0.249072  ...  0.409665 -0.106801 -0.285788   \n",
              "\n",
              "           94        95        96        97        98        99        100  \n",
              "0                                                                           \n",
              "nahi -0.099099  0.271938  0.311072 -0.446256 -0.093532  0.118786 -0.221102  \n",
              "to   -0.110159 -0.012980  0.211806 -0.197437  0.094797 -0.070250 -0.186570  \n",
              "ki   -0.015633  0.151389  0.332968 -0.311262  0.057184 -0.281329 -0.346765  \n",
              "ke   -0.108783  0.322591  0.347032 -0.558663 -0.018923  0.116121 -0.325165  \n",
              "se    0.028810  0.064475  0.117800 -0.666445 -0.167434 -0.310887 -0.367422  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_embedding.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJaOLL02TmUy"
      },
      "source": [
        "### Create vocab dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456blVxHEqJK",
        "outputId": "1fabfa5e-e9db-40dc-ab0d-d166d43011d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = df_embedding.to_numpy()\n",
        "m.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKURV7-5NXfE",
        "outputId": "aa55221f-8b72-43cf-ead5-c93cc46fc391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix = df_embedding.to_numpy()\n",
        "\n",
        "vocab = []\n",
        "\n",
        "for word in list(df_embedding.index):\n",
        "  vocab.append(str(word))\n",
        "\n",
        "vocab_size , vocab_dim = embedding_matrix.shape\n",
        "vocab_size, vocab_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHZGs3aFF6b",
        "outputId": "a2d76acf-4109-40cb-f952-a38c12680201"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40599"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Rju-5mvbVp6H"
      },
      "outputs": [],
      "source": [
        "word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY77Ru_NFMMs",
        "outputId": "45e84371-3f06-494c-dfb6-4ec87e2edd77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40598, 40599)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2idx) , len(idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBRDCquFF62W",
        "outputId": "ce912395-b2d0-479c-d114-549f630f681d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nahi': 0,\n",
              " 'to': 1,\n",
              " 'ki': 2,\n",
              " 'ke': 3,\n",
              " 'se': 4,\n",
              " 'ko': 5,\n",
              " 'the': 6,\n",
              " 'ka': 7,\n",
              " 'me': 8,\n",
              " 'bhi': 9}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "dict(itertools.islice(word2idx.items(), 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0HS8bPTqWq"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSukKoeeNvSs",
        "outputId": "ac5d640e-fe25-4325-8fd9-cda5c59e06d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9500 9500\n",
            "1000 1000\n",
            "2101 2101\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/home/ckm/ck_project/codemix/code/selfnet_mihir/Hindi_English_SAIL.csv')\n",
        "df= df.sample(frac = 1)\n",
        "\n",
        "train_df = df[:9500]\n",
        "val_df = df[9500:10500]\n",
        "test_df = df[10500:]\n",
        "\n",
        "train_df.head()\n",
        "\n",
        "\n",
        "train_data =  train_df['Sentence'].values.astype(str)\n",
        "train_labels = train_df['Label'].values\n",
        "train_labels = [int(label) for label in train_labels]\n",
        "\n",
        "val_data =  val_df['Sentence'].values.astype(str)\n",
        "val_labels = val_df['Label'].values\n",
        "val_labels = [int(label) for label in val_labels]\n",
        "\n",
        "test_data =  test_df['Sentence'].values.astype(str)\n",
        "test_labels = test_df['Label'].values\n",
        "test_labels = [int(label) for label in test_labels]\n",
        "\n",
        "print(len(train_data), len(train_labels))\n",
        "print(len(val_data), len(val_labels))\n",
        "print(len(test_data), len(test_labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FMJNuKrDn-xb",
        "outputId": "0d136085-6d5e-44c5-c7ae-13f046263e35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>garbage bin bhai batao na mera comment pahla h...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2859</th>\n",
              "      <td>abhe yeh really salman ki id h kya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>its not guddu's fault . . . . . prestige ka hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11227</th>\n",
              "      <td>Apne dil jeet lia bhai...Allah bless you</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>my brother used to do these thngs for me , , h...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Sentence  Label\n",
              "80     garbage bin bhai batao na mera comment pahla h...      2\n",
              "2859                  abhe yeh really salman ki id h kya      2\n",
              "508    its not guddu's fault . . . . . prestige ka hi...      0\n",
              "11227           Apne dil jeet lia bhai...Allah bless you      0\n",
              "527    my brother used to do these thngs for me , , h...      2"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "83AlL80DN1_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# post = pd.read_csv(\"positive_add1and2.csv\",sep=',')\n",
        "# neg = pd.read_csv(\"negative_add_1and2.csv\",sep=',')\n",
        "\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "# for index, row in post.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(1)\n",
        "\n",
        "\n",
        "# for index, row in neg.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(0)\n",
        "  \n",
        "\n",
        "# len(data), len(labels)\n",
        "\n",
        "# data, labels  = shuffle(data, labels, random_state = 40)\n",
        "\n",
        "# data[0], labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5iYXAJbTwJ8"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "QgF5Hb8weYwB"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "\n",
        "def tokenized_tensor(data):\n",
        "\n",
        "  output_tokenized = []\n",
        "\n",
        "  for sentence in data:\n",
        "    output = []\n",
        "    tokenized = tokenizer(sentence)\n",
        "    \n",
        "    for word in tokenized:\n",
        "      if word in word2idx:\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "      else:\n",
        "        word2idx[word] = len(word2idx)\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "\n",
        "    output = torch.tensor(output)\n",
        "\n",
        "\n",
        "    output_tokenized.append(output)\n",
        "\n",
        "  return output_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "K_pDpPLhiUPG"
      },
      "outputs": [],
      "source": [
        "# tokenized_sequences = tokenized_tensor(data)\n",
        "\n",
        "train_tokenized_sequences = tokenized_tensor(train_data)\n",
        "\n",
        "test_tokenized_seuqences = tokenized_tensor(test_data)\n",
        "\n",
        "val_tokenized_seuquences = tokenized_tensor(val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6WOxrifIFKQ",
        "outputId": "ef207cd4-55fc-456f-bc8e-adaadbe1cc96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([17297,   110,   455,  5316,     2,  3563,    28,    24])\n"
          ]
        }
      ],
      "source": [
        "print(train_tokenized_sequences[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poFrSB5Opl1-",
        "outputId": "0bad193a-cf73-4f71-e6e9-509bfec95058"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53012"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2idx['<PAD>'] = len(word2idx)\n",
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9AZYccLbVof",
        "outputId": "bf73d6d9-113b-4880-9a85-a27c29d13ae9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53013"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "GYstutbgrABv"
      },
      "outputs": [],
      "source": [
        "## Create embedding matrix\n",
        "\n",
        "random_init = torch.nn.Parameter(torch.Tensor( (len(word2idx) - vocab_size), vocab_dim))\n",
        "torch.nn.init.kaiming_uniform_(random_init, a=math.sqrt(5))\n",
        "\n",
        "\n",
        "new_matrix = np.zeros( (len(word2idx), vocab_dim) )\n",
        "\n",
        "new_matrix[:vocab_size, :] = embedding_matrix\n",
        "\n",
        "embedding_matrix = new_matrix\n",
        "\n",
        "embedding_matrix[vocab_size:, :] = random_init.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0mL0x6J3KV",
        "outputId": "32d4bf4d-7ec2-4085-fce3-6c7b82f0922a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53013, 100)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53013, 100)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "3cp0nnNdrazK"
      },
      "outputs": [],
      "source": [
        "# padded_sequences = pad_sequence(tokenized_sequences, batch_first= True, padding_value=107512)\n",
        "\n",
        "train_padded_sequences = pad_sequence(train_tokenized_sequences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "val_padded_sequences = pad_sequence(val_tokenized_seuquences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "test_padded_sequences = pad_sequence(test_tokenized_seuqences, batch_first= True, padding_value=word2idx['<PAD>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trl1D4QFII3e",
        "outputId": "281787e8-4bbd-4b9c-dea0-6f937b0b3f9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([17297,   110,   455,  5316,     2,  3563,    28,    24, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "        53012, 53012, 53012, 53012, 53012, 53012])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_padded_sequences[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSE4xlb2O8Ju"
      },
      "source": [
        "### Dataset and Data loader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ISg-6szPOBr1"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
        "    \"\"\"\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.labels = labels\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        sequence = self.sequences[idx]\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        try:\n",
        "            sample[\"label\"] = label\n",
        "            sample[\"token\"] = sequence\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "L1LEy0ogII3g"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_padded_sequences, train_labels)\n",
        "\n",
        "val_dataset = Dataset(val_padded_sequences, val_labels)\n",
        "\n",
        "test_dataset = Dataset(test_padded_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQVUtYvII3g"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC2nFBOTynbR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ENWuqJHeII3h"
      },
      "outputs": [],
      "source": [
        "## Hyper parameter\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "embed_dim = vocab_dim\n",
        "seq_len = 192\n",
        "hidden_size = 512\n",
        "num_layer = 3\n",
        "num_class = 3\n",
        "batch_size = 32\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 30\n",
        "CLIP = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "R2daJrk6PQb7"
      },
      "outputs": [],
      "source": [
        "# # Create datasets\n",
        "# dataset = Dataset(padded_sequences, labels)\n",
        "\n",
        "# split = 0.85\n",
        "# train_size = int(split*len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "LSYO1yrqPSgn"
      },
      "outputs": [],
      "source": [
        "\n",
        "## We call the dataloader class\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "## For testing\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "\n",
        "dataloaders = {'Train': train_loader, 'Val': val_loader}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ZYd39BII3i",
        "outputId": "3a10a91c-2116-4ada-e1f6-e3abc17ea147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(296, 31, 65)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoA6yF7iomTV",
        "outputId": "418e1523-d735-4082-f963-16580e8ea844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60\n"
          ]
        }
      ],
      "source": [
        "max_len = -1\n",
        "for comment in val_dataset:\n",
        "  sentence = comment['token']\n",
        "  max_len = max(max_len,sentence.shape[0])\n",
        "\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0DXO4Q2II3i",
        "outputId": "471b3762-68ba-4ac6-8f4c-2acd20a5b427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'label': tensor(2),\n",
              " 'token': tensor([ 9964,  2901,    74,   859,    29,    39,  1110, 13667, 40598,    29,\n",
              "         40599, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012, 53012,\n",
              "         53012, 53012, 53012, 53012, 53012, 53012])}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXQNerMvjIb"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "wR0tnE2NxphD"
      },
      "outputs": [],
      "source": [
        "class SelfMatchingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,  seq_length, embed_dim, **kwargs):\n",
        "\n",
        "      super(SelfMatchingLayer, self).__init__()\n",
        "\n",
        "      self.seq_length = seq_length\n",
        "      self.embed_dim  = embed_dim\n",
        "\n",
        "      self.P = torch.nn.Parameter(torch.Tensor(self.embed_dim, self.embed_dim))\n",
        "\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.P, a=math.sqrt(5))\n",
        "\n",
        "      \n",
        "    def forward(self, x):  \n",
        "      \n",
        "      # input shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "\n",
        "      #---------------------------------------------#\n",
        "      # calculate weight vector a = {e_i . P.Q . e_j}\n",
        "      #---------------------------------------------#\n",
        "\n",
        "      out = torch.matmul(x,  self.P)   #out shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "      out = torch.matmul(out, torch.transpose(x, 1, 2))   #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = F.gelu(out)         # apply non linear activation\n",
        "\n",
        "      #------------------------------------#\n",
        "      # take row wise mean and apply softmax\n",
        "      #------------------------------------#\n",
        "      out = torch.mean(out, 2)  #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = torch.softmax(out, 0)     #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = out.unsqueeze(1)          #out shape: [batch, 1, seq_len]\n",
        "\n",
        "      #-------------------------------------------#\n",
        "      # calculate weighted embedding of every word\n",
        "      #-------------------------------------------#\n",
        "      out = torch.matmul(out, x)\n",
        "\n",
        "      out = out.squeeze(1)\n",
        "\n",
        "      return out      #out shape: [batch, seq_len]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkC2PE1q3Fq",
        "outputId": "5188e8ce-3efa-4280-f761-511c46f26e2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53012"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "LFAeZSyXu9KJ"
      },
      "outputs": [],
      "source": [
        "class SelfNet(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class):\n",
        "        super(SelfNet, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = word2idx['<PAD>'])\n",
        "        self.embedding.load_state_dict({'weight': torch.from_numpy(embedding_matrix)})\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        self.selfnet_layer = SelfMatchingLayer(seq_len, embed_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = num_layer, dropout = 0.3, bidirectional = True, batch_first = True )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2* hidden_size + embed_dim , hidden_size//4)\n",
        "        self.fc2 = nn.Linear(hidden_size//4, num_class)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        embedded = self.embedding(input)  #out shape = [batch, seq_len, embed_dim] \n",
        "\n",
        "        selfmatch_output = self.selfnet_layer(embedded)  #out shape = [batch, seq_len] \n",
        "\n",
        "        lstm_out, _ = self.lstm(embedded)     \n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]      #out shape = [batch, 2 * hidden_size]      \n",
        "\n",
        "        concat = torch.cat( (selfmatch_output, lstm_out), 1)     #out shape = [batch, 2 * hidden_size + seq_len ]      \n",
        "\n",
        "        linear_out = self.dropout(F.relu(self.fc1(concat)))     #out shape = [batch, hidden_size]      \n",
        "\n",
        "        final_out = self.fc2(linear_out)     #out shape = [batch, 2]      \n",
        "\n",
        "        return final_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Msc1-1zlOtAh"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Test\n",
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\n",
        "model = model.to(device)\n",
        "\n",
        "# for batch in train_loader:\n",
        "#   x = batch['token'].to(device)\n",
        "#   out = model(x)\n",
        "#   print(out.shape)\n",
        "#   break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-XvE3WHII3l",
        "outputId": "aaf727e6-066f-49bc-d07b-e32dfa27a9a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(53013, 100, padding_idx=53012)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xjqPfmqx5Hj"
      },
      "source": [
        "### Optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ifFhRpc2x4Fv"
      },
      "outputs": [],
      "source": [
        "#optimizer\n",
        "optimizer = Adam(model.parameters(), lr = LEARNING_RATE, eps=1e-8)\n",
        "#Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "04ozLaUUx-eo"
      },
      "outputs": [],
      "source": [
        "#to calculate accuracy\n",
        "\n",
        "def get_accuracy(preds, labels):\n",
        "  total_acc = 0.0\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    if labels[i] == preds[i]:\n",
        "      total_acc+=1.0\n",
        "  \n",
        "  return total_acc / len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D33SEPjzILZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP5of6JbII3n",
        "outputId": "58296fc2-81e5-4394-eec6-d979870d53b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5, verbose = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "2o0-BUMKII3o"
      },
      "outputs": [],
      "source": [
        "PATH = '/home/ckm/ck_project/codemix/models/selfnet_mean+gelu_SAIL.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZkPq1t6yBwx",
        "outputId": "4a678302-dc2f-421d-a886-c7448087ca26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:30<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.3347, Precision: 0.4124, Recall : 0.4560, Accuracy: 0.4560, Loss: 0.0078.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4323, Precision: 0.4869, Recall : 0.4335, Accuracy: 0.4335, Loss: 0.0692.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 5.0000e-04.\n",
            "--------------------------------------------------\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:36<00:00,  1.07batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.4634, Precision: 0.5016, Recall : 0.5119, Accuracy: 0.5119, Loss: 0.0063.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.07batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4363, Precision: 0.5295, Recall : 0.4546, Accuracy: 0.4546, Loss: 0.0671.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 2.5000e-04.\n",
            "--------------------------------------------------\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:28<00:00,  1.10batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5188, Precision: 0.5506, Recall : 0.5509, Accuracy: 0.5509, Loss: 0.0080.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4641, Precision: 0.5384, Recall : 0.4748, Accuracy: 0.4748, Loss: 0.0688.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.2500e-04.\n",
            "--------------------------------------------------\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:31<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5439, Precision: 0.5713, Recall : 0.5699, Accuracy: 0.5699, Loss: 0.0062.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.10batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4716, Precision: 0.5441, Recall : 0.4819, Accuracy: 0.4819, Loss: 0.0717.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 6.2500e-05.\n",
            "--------------------------------------------------\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:36<00:00,  1.07batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5582, Precision: 0.5848, Recall : 0.5821, Accuracy: 0.5821, Loss: 0.0061.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4656, Precision: 0.5454, Recall : 0.4748, Accuracy: 0.4748, Loss: 0.0705.\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.1250e-05.\n",
            "--------------------------------------------------\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:35<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5636, Precision: 0.5909, Recall : 0.5864, Accuracy: 0.5864, Loss: 0.0048.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4736, Precision: 0.5531, Recall : 0.4788, Accuracy: 0.4788, Loss: 0.0676.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.5625e-05.\n",
            "--------------------------------------------------\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:31<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5665, Precision: 0.5925, Recall : 0.5889, Accuracy: 0.5889, Loss: 0.0068.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4785, Precision: 0.5566, Recall : 0.4869, Accuracy: 0.4869, Loss: 0.0673.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 7.8125e-06.\n",
            "--------------------------------------------------\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:30<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5690, Precision: 0.5945, Recall : 0.5911, Accuracy: 0.5911, Loss: 0.0063.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  7.96batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4747, Precision: 0.5474, Recall : 0.4819, Accuracy: 0.4819, Loss: 0.0683.\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.9063e-06.\n",
            "--------------------------------------------------\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:31<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5707, Precision: 0.5970, Recall : 0.5926, Accuracy: 0.5926, Loss: 0.0069.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4671, Precision: 0.5538, Recall : 0.4768, Accuracy: 0.4768, Loss: 0.0690.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.9531e-06.\n",
            "--------------------------------------------------\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:31<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5705, Precision: 0.5982, Recall : 0.5930, Accuracy: 0.5930, Loss: 0.0059.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.01batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4702, Precision: 0.5457, Recall : 0.4798, Accuracy: 0.4798, Loss: 0.0656.\n",
            "\n",
            "Adjusting learning rate of group 0 to 9.7656e-07.\n",
            "--------------------------------------------------\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:32<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5718, Precision: 0.5986, Recall : 0.5941, Accuracy: 0.5941, Loss: 0.0065.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4697, Precision: 0.5463, Recall : 0.4778, Accuracy: 0.4778, Loss: 0.0670.\n",
            "\n",
            "Adjusting learning rate of group 0 to 4.8828e-07.\n",
            "--------------------------------------------------\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:27<00:00,  1.11batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5657, Precision: 0.5934, Recall : 0.5884, Accuracy: 0.5884, Loss: 0.0064.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4675, Precision: 0.5418, Recall : 0.4748, Accuracy: 0.4748, Loss: 0.0720.\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.4414e-07.\n",
            "--------------------------------------------------\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:28<00:00,  1.10batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5681, Precision: 0.5951, Recall : 0.5901, Accuracy: 0.5901, Loss: 0.0054.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.11batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4748, Precision: 0.5553, Recall : 0.4829, Accuracy: 0.4829, Loss: 0.0675.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2207e-07.\n",
            "--------------------------------------------------\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:33<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5637, Precision: 0.5900, Recall : 0.5860, Accuracy: 0.5860, Loss: 0.0054.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.23batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4719, Precision: 0.5492, Recall : 0.4778, Accuracy: 0.4778, Loss: 0.0675.\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.1035e-08.\n",
            "--------------------------------------------------\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:33<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5665, Precision: 0.5933, Recall : 0.5893, Accuracy: 0.5893, Loss: 0.0057.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4623, Precision: 0.5431, Recall : 0.4718, Accuracy: 0.4718, Loss: 0.0681.\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.0518e-08.\n",
            "--------------------------------------------------\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:31<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5702, Precision: 0.5967, Recall : 0.5918, Accuracy: 0.5918, Loss: 0.0059.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4624, Precision: 0.5486, Recall : 0.4687, Accuracy: 0.4688, Loss: 0.0656.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.5259e-08.\n",
            "--------------------------------------------------\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:36<00:00,  1.07batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5644, Precision: 0.5910, Recall : 0.5871, Accuracy: 0.5871, Loss: 0.0072.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.18batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4606, Precision: 0.5426, Recall : 0.4688, Accuracy: 0.4688, Loss: 0.0641.\n",
            "\n",
            "Adjusting learning rate of group 0 to 7.6294e-09.\n",
            "--------------------------------------------------\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:32<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5689, Precision: 0.5965, Recall : 0.5909, Accuracy: 0.5909, Loss: 0.0062.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4641, Precision: 0.5492, Recall : 0.4708, Accuracy: 0.4708, Loss: 0.0668.\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.8147e-09.\n",
            "--------------------------------------------------\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:33<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5692, Precision: 0.5969, Recall : 0.5913, Accuracy: 0.5913, Loss: 0.0065.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.11batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4700, Precision: 0.5445, Recall : 0.4768, Accuracy: 0.4768, Loss: 0.0659.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.9073e-09.\n",
            "--------------------------------------------------\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:38<00:00,  1.06batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5719, Precision: 0.5979, Recall : 0.5932, Accuracy: 0.5932, Loss: 0.0063.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4610, Precision: 0.5444, Recall : 0.4708, Accuracy: 0.4708, Loss: 0.0682.\n",
            "\n",
            "Adjusting learning rate of group 0 to 9.5367e-10.\n",
            "--------------------------------------------------\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:32<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5671, Precision: 0.5936, Recall : 0.5901, Accuracy: 0.5901, Loss: 0.0062.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.06batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4667, Precision: 0.5472, Recall : 0.4758, Accuracy: 0.4758, Loss: 0.0655.\n",
            "\n",
            "Adjusting learning rate of group 0 to 4.7684e-10.\n",
            "--------------------------------------------------\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:34<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5648, Precision: 0.5895, Recall : 0.5866, Accuracy: 0.5866, Loss: 0.0063.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4523, Precision: 0.5314, Recall : 0.4627, Accuracy: 0.4627, Loss: 0.0672.\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.3842e-10.\n",
            "--------------------------------------------------\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:26<00:00,  1.11batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5698, Precision: 0.5964, Recall : 0.5915, Accuracy: 0.5915, Loss: 0.0066.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4611, Precision: 0.5410, Recall : 0.4718, Accuracy: 0.4718, Loss: 0.0668.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.1921e-10.\n",
            "--------------------------------------------------\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:34<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5669, Precision: 0.5923, Recall : 0.5897, Accuracy: 0.5897, Loss: 0.0055.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.17batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4640, Precision: 0.5405, Recall : 0.4728, Accuracy: 0.4728, Loss: 0.0664.\n",
            "\n",
            "Adjusting learning rate of group 0 to 5.9605e-11.\n",
            "--------------------------------------------------\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:28<00:00,  1.10batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5630, Precision: 0.5888, Recall : 0.5857, Accuracy: 0.5857, Loss: 0.0058.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.20batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4589, Precision: 0.5363, Recall : 0.4688, Accuracy: 0.4688, Loss: 0.0709.\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.9802e-11.\n",
            "--------------------------------------------------\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:35<00:00,  1.07batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5671, Precision: 0.5933, Recall : 0.5892, Accuracy: 0.5892, Loss: 0.0065.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4663, Precision: 0.5435, Recall : 0.4728, Accuracy: 0.4728, Loss: 0.0682.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.4901e-11.\n",
            "--------------------------------------------------\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:31<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5704, Precision: 0.5965, Recall : 0.5926, Accuracy: 0.5926, Loss: 0.0055.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4522, Precision: 0.5335, Recall : 0.4627, Accuracy: 0.4627, Loss: 0.0674.\n",
            "\n",
            "Adjusting learning rate of group 0 to 7.4506e-12.\n",
            "--------------------------------------------------\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:32<00:00,  1.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5655, Precision: 0.5907, Recall : 0.5877, Accuracy: 0.5877, Loss: 0.0059.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.08batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4629, Precision: 0.5452, Recall : 0.4708, Accuracy: 0.4708, Loss: 0.0676.\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.7253e-12.\n",
            "--------------------------------------------------\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:32<00:00,  1.09batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5691, Precision: 0.5961, Recall : 0.5917, Accuracy: 0.5917, Loss: 0.0069.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4705, Precision: 0.5454, Recall : 0.4798, Accuracy: 0.4798, Loss: 0.0697.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.8626e-12.\n",
            "--------------------------------------------------\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296/296 [04:29<00:00,  1.10batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5687, Precision: 0.5939, Recall : 0.5913, Accuracy: 0.5913, Loss: 0.0066.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:03<00:00,  8.04batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4647, Precision: 0.5478, Recall : 0.4718, Accuracy: 0.4718, Loss: 0.0678.\n",
            "\n",
            "Adjusting learning rate of group 0 to 9.3132e-13.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_valid_f1 = 0.0000\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "  \n",
        "\n",
        "    print('-'*50)\n",
        "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
        "\n",
        "    for phase in ['Train', 'Val']:\n",
        "\n",
        "        loss = 0.0   #epoch loss\n",
        "        accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        if phase == 'Train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        \n",
        "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
        "\n",
        "          for batch in tepoch:\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            text = batch[\"token\"].to(device)\n",
        "            \n",
        "\n",
        "            output = model(text)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            if phase == 'Train':\n",
        "\n",
        "                #zero gradients\n",
        "                optimizer.zero_grad() \n",
        "\n",
        "                # Backward pass  (calculates the gradients)\n",
        "                loss.backward()   \n",
        "\n",
        "                # gradient clipping\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
        "\n",
        "                optimizer.step()             # Updates the weights    \n",
        "\n",
        "            sleep(0.1)\n",
        "            _, preds = output.data.max(1)\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "            \n",
        "            batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "            \n",
        "            \n",
        "            loss += loss.item()\n",
        "            accuracy+= batch_acc\n",
        "\n",
        "              \n",
        "          epoch_loss = loss / (len(dataloaders[phase]))\n",
        "          epoch_acc = accuracy / (len(dataloaders[phase]))\n",
        "\n",
        "          print(phase + \":\")\n",
        "          \n",
        "          \n",
        "          #print(confusion_matrix(y_true, y_pred))\n",
        "          pre = precision_score(y_true, y_pred, average='weighted')\n",
        "          recall = recall_score(y_true, y_pred, average='weighted')\n",
        "          f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "          \n",
        "\n",
        "          print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))\n",
        "          # save best model\n",
        "          print()\n",
        "          \n",
        "            \n",
        "          if phase == 'Val':\n",
        "                \n",
        "                if f1 > best_valid_f1:\n",
        "                    best_valid_f1 = f1\n",
        "                    \n",
        "                    torch.save(model.state_dict(), PATH)\n",
        "                    print('Model Saved!')\n",
        "                    \n",
        "                scheduler.step()\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yJchRvUz2nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsq5MiaHII3r"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "0L66ZUsoII3r"
      },
      "outputs": [],
      "source": [
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "EceKQVWTII3r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(53013, 100, padding_idx=53012)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "A1DB4Su5II3r"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 65/65 [00:27<00:00,  2.34batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[207  51 410]\n",
            " [ 43 113 278]\n",
            " [ 77  63 838]]\n",
            "\n",
            "F1: 0.5567, Precision: 0.5567, Recall : 0.5567, Accuracy: 1.1673, Loss: 0.0540.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "X99rC-LvII3s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(53013, 100, padding_idx=53012)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "EQwRQc_NII3s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 65/65 [00:26<00:00,  2.50batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[206  58 403]\n",
            " [ 41 116 281]\n",
            " [ 74  77 824]]\n",
            "\n",
            "F1: 0.5157, Precision: 0.5592, Recall : 0.5510, Accuracy: 1.1552, Loss: 0.0619.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "wQs04_VAII3t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 65/65 [00:28<00:00,  2.29batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[206  55 402]\n",
            " [ 45 120 270]\n",
            " [ 78  69 835]]\n",
            "\n",
            "F1: 0.5582, Precision: 0.5582, Recall : 0.5582, Accuracy: 1.1704, Loss: 0.0624.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6Kth3CNII3t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMwq-cvgKn1w"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "SelfNet_mean_+_gelu_Youtube_Comments.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "80812c57c454a5cb47da895f264233db0a5d87621772a622276e795be9a4c20f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('python3.7': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
