{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "YouTube Comments dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YagaAp_xTg6W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (0.11.0)\n",
            "Requirement already satisfied: torch==1.10.0 in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from torchtext) (1.10.0)\n",
            "Requirement already satisfied: requests in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from torchtext) (2.25.1)\n",
            "Requirement already satisfied: numpy in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from torchtext) (4.56.2)\n",
            "Requirement already satisfied: typing-extensions in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from torch==1.10.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from torch==1.10.0->torchtext) (0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from requests->torchtext) (1.26.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ckm/sarcasm_detection/film-master/.env/lib/python3.6/site-packages (from requests->torchtext) (4.0.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/home/ckm/sarcasm_detection/film-master/.env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PSSRsC1fNADr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muafgoq3zdah",
        "outputId": "cd656d64-7473-458b-a6ed-4d04a16d7ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec 23 11:21:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-PCIE...  Off  | 00000000:17:00.0 Off |                    0 |\n",
            "| N/A   79C    P0   203W / 250W |  12052MiB / 16160MiB |    100%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      4564      C   ./darknet                       12044MiB |\n",
            "|    0   N/A  N/A      9726      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "+-----------------------------------------------------------------------------+\n",
            "WARNING: infoROM is corrupted at gpu 0000:17:00.0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4B0ARAXTkLp"
      },
      "source": [
        "### Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HzzoO4vmNW1V"
      },
      "outputs": [],
      "source": [
        "datapath = \"/home/ckm/ck_project/codemix/code/selfnet_mihir/\"\n",
        "df_embedding = pd.read_csv(datapath+'hing_emb', sep=\" \", quoting=3, header=None, index_col=0,skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2Wnirn_1ERuU",
        "outputId": "94f9f804-6f56-40c5-b8cb-6c083d841b70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nahi</th>\n",
              "      <td>-0.079912</td>\n",
              "      <td>0.522077</td>\n",
              "      <td>0.009111</td>\n",
              "      <td>-0.103475</td>\n",
              "      <td>-0.042439</td>\n",
              "      <td>0.229031</td>\n",
              "      <td>0.360524</td>\n",
              "      <td>0.047913</td>\n",
              "      <td>0.129397</td>\n",
              "      <td>0.184819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049488</td>\n",
              "      <td>-0.291750</td>\n",
              "      <td>0.188353</td>\n",
              "      <td>-0.099099</td>\n",
              "      <td>0.271938</td>\n",
              "      <td>0.311072</td>\n",
              "      <td>-0.446256</td>\n",
              "      <td>-0.093532</td>\n",
              "      <td>0.118786</td>\n",
              "      <td>-0.221102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.268486</td>\n",
              "      <td>0.454443</td>\n",
              "      <td>-0.211620</td>\n",
              "      <td>-0.029896</td>\n",
              "      <td>-0.123828</td>\n",
              "      <td>0.119760</td>\n",
              "      <td>0.146776</td>\n",
              "      <td>0.152356</td>\n",
              "      <td>0.136670</td>\n",
              "      <td>-0.086144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.256750</td>\n",
              "      <td>0.170485</td>\n",
              "      <td>-0.081619</td>\n",
              "      <td>-0.110159</td>\n",
              "      <td>-0.012980</td>\n",
              "      <td>0.211806</td>\n",
              "      <td>-0.197437</td>\n",
              "      <td>0.094797</td>\n",
              "      <td>-0.070250</td>\n",
              "      <td>-0.186570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ki</th>\n",
              "      <td>-0.342798</td>\n",
              "      <td>0.568509</td>\n",
              "      <td>0.049298</td>\n",
              "      <td>-0.111945</td>\n",
              "      <td>-0.312412</td>\n",
              "      <td>0.490620</td>\n",
              "      <td>0.442846</td>\n",
              "      <td>0.053863</td>\n",
              "      <td>0.177461</td>\n",
              "      <td>0.111002</td>\n",
              "      <td>...</td>\n",
              "      <td>0.491238</td>\n",
              "      <td>-0.074531</td>\n",
              "      <td>0.165319</td>\n",
              "      <td>-0.015633</td>\n",
              "      <td>0.151389</td>\n",
              "      <td>0.332968</td>\n",
              "      <td>-0.311262</td>\n",
              "      <td>0.057184</td>\n",
              "      <td>-0.281329</td>\n",
              "      <td>-0.346765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ke</th>\n",
              "      <td>-0.299528</td>\n",
              "      <td>0.510413</td>\n",
              "      <td>-0.033908</td>\n",
              "      <td>-0.064933</td>\n",
              "      <td>-0.439092</td>\n",
              "      <td>0.359395</td>\n",
              "      <td>0.342511</td>\n",
              "      <td>-0.102557</td>\n",
              "      <td>0.354761</td>\n",
              "      <td>0.632507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202599</td>\n",
              "      <td>-0.206487</td>\n",
              "      <td>0.178269</td>\n",
              "      <td>-0.108783</td>\n",
              "      <td>0.322591</td>\n",
              "      <td>0.347032</td>\n",
              "      <td>-0.558663</td>\n",
              "      <td>-0.018923</td>\n",
              "      <td>0.116121</td>\n",
              "      <td>-0.325165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>se</th>\n",
              "      <td>-0.435697</td>\n",
              "      <td>0.357603</td>\n",
              "      <td>-0.040995</td>\n",
              "      <td>0.107330</td>\n",
              "      <td>-0.313671</td>\n",
              "      <td>0.268082</td>\n",
              "      <td>0.246396</td>\n",
              "      <td>0.005616</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>0.249072</td>\n",
              "      <td>...</td>\n",
              "      <td>0.409665</td>\n",
              "      <td>-0.106801</td>\n",
              "      <td>-0.285788</td>\n",
              "      <td>0.028810</td>\n",
              "      <td>0.064475</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>-0.666445</td>\n",
              "      <td>-0.167434</td>\n",
              "      <td>-0.310887</td>\n",
              "      <td>-0.367422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           1         2         3         4         5         6         7    \\\n",
              "0                                                                            \n",
              "nahi -0.079912  0.522077  0.009111 -0.103475 -0.042439  0.229031  0.360524   \n",
              "to    0.268486  0.454443 -0.211620 -0.029896 -0.123828  0.119760  0.146776   \n",
              "ki   -0.342798  0.568509  0.049298 -0.111945 -0.312412  0.490620  0.442846   \n",
              "ke   -0.299528  0.510413 -0.033908 -0.064933 -0.439092  0.359395  0.342511   \n",
              "se   -0.435697  0.357603 -0.040995  0.107330 -0.313671  0.268082  0.246396   \n",
              "\n",
              "           8         9         10   ...       91        92        93   \\\n",
              "0                                   ...                                 \n",
              "nahi  0.047913  0.129397  0.184819  ...  0.049488 -0.291750  0.188353   \n",
              "to    0.152356  0.136670 -0.086144  ...  0.256750  0.170485 -0.081619   \n",
              "ki    0.053863  0.177461  0.111002  ...  0.491238 -0.074531  0.165319   \n",
              "ke   -0.102557  0.354761  0.632507  ...  0.202599 -0.206487  0.178269   \n",
              "se    0.005616  0.089185  0.249072  ...  0.409665 -0.106801 -0.285788   \n",
              "\n",
              "           94        95        96        97        98        99        100  \n",
              "0                                                                           \n",
              "nahi -0.099099  0.271938  0.311072 -0.446256 -0.093532  0.118786 -0.221102  \n",
              "to   -0.110159 -0.012980  0.211806 -0.197437  0.094797 -0.070250 -0.186570  \n",
              "ki   -0.015633  0.151389  0.332968 -0.311262  0.057184 -0.281329 -0.346765  \n",
              "ke   -0.108783  0.322591  0.347032 -0.558663 -0.018923  0.116121 -0.325165  \n",
              "se    0.028810  0.064475  0.117800 -0.666445 -0.167434 -0.310887 -0.367422  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_embedding.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJaOLL02TmUy"
      },
      "source": [
        "### Create vocab dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456blVxHEqJK",
        "outputId": "1fabfa5e-e9db-40dc-ab0d-d166d43011d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = df_embedding.to_numpy()\n",
        "m.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKURV7-5NXfE",
        "outputId": "aa55221f-8b72-43cf-ead5-c93cc46fc391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40599, 100)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix = df_embedding.to_numpy()\n",
        "\n",
        "vocab = []\n",
        "\n",
        "for word in list(df_embedding.index):\n",
        "  vocab.append(str(word))\n",
        "\n",
        "vocab_size , vocab_dim = embedding_matrix.shape\n",
        "vocab_size, vocab_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHZGs3aFF6b",
        "outputId": "a2d76acf-4109-40cb-f952-a38c12680201"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40599"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rju-5mvbVp6H"
      },
      "outputs": [],
      "source": [
        "word2idx = {w: idx for (idx, w) in enumerate(vocab)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY77Ru_NFMMs",
        "outputId": "45e84371-3f06-494c-dfb6-4ec87e2edd77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40598, 40599)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2idx) , len(idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBRDCquFF62W",
        "outputId": "ce912395-b2d0-479c-d114-549f630f681d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nahi': 0,\n",
              " 'to': 1,\n",
              " 'ki': 2,\n",
              " 'ke': 3,\n",
              " 'se': 4,\n",
              " 'ko': 5,\n",
              " 'the': 6,\n",
              " 'ka': 7,\n",
              " 'me': 8,\n",
              " 'bhi': 9}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "dict(itertools.islice(word2idx.items(), 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0HS8bPTqWq"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSukKoeeNvSs",
        "outputId": "ac5d640e-fe25-4325-8fd9-cda5c59e06d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9500 9500\n",
            "1000 1000\n",
            "2101 2101\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/home/ckm/ck_project/codemix/code/selfnet_mihir/Hindi_English_SAIL.csv')\n",
        "df= df.sample(frac = 1)\n",
        "\n",
        "train_df = df[:9500]\n",
        "val_df = df[9500:10500]\n",
        "test_df = df[10500:]\n",
        "\n",
        "train_df.head()\n",
        "\n",
        "\n",
        "train_data =  train_df['Sentence'].values.astype(str)\n",
        "train_labels = train_df['Label'].values\n",
        "train_labels = [int(label) for label in train_labels]\n",
        "\n",
        "val_data =  val_df['Sentence'].values.astype(str)\n",
        "val_labels = val_df['Label'].values\n",
        "val_labels = [int(label) for label in val_labels]\n",
        "\n",
        "test_data =  test_df['Sentence'].values.astype(str)\n",
        "test_labels = test_df['Label'].values\n",
        "test_labels = [int(label) for label in test_labels]\n",
        "\n",
        "print(len(train_data), len(train_labels))\n",
        "print(len(val_data), len(val_labels))\n",
        "print(len(test_data), len(test_labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FMJNuKrDn-xb",
        "outputId": "0d136085-6d5e-44c5-c7ae-13f046263e35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>Weka tak nai chalra</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9495</th>\n",
              "      <td>liverpool looking to activate demba ba's 7m bu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3590</th>\n",
              "      <td>bhai thik hain</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7739</th>\n",
              "      <td>N wts \"the status\"</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Manage kar lenge sab</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Sentence  Label\n",
              "270                                 Weka tak nai chalra      0\n",
              "9495  liverpool looking to activate demba ba's 7m bu...      2\n",
              "3590                                     bhai thik hain      0\n",
              "7739                                 N wts \"the status\"      2\n",
              "37                                 Manage kar lenge sab      2"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "83AlL80DN1_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# post = pd.read_csv(\"positive_add1and2.csv\",sep=',')\n",
        "# neg = pd.read_csv(\"negative_add_1and2.csv\",sep=',')\n",
        "\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "# for index, row in post.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(1)\n",
        "\n",
        "\n",
        "# for index, row in neg.iterrows():\n",
        "#   if index >= 30000:\n",
        "#     break\n",
        "  \n",
        "#   comment = str(row['tweet'])\n",
        "#   data.append(comment)\n",
        "#   labels.append(0)\n",
        "  \n",
        "\n",
        "# len(data), len(labels)\n",
        "\n",
        "# data, labels  = shuffle(data, labels, random_state = 40)\n",
        "\n",
        "# data[0], labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5iYXAJbTwJ8"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QgF5Hb8weYwB"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "\n",
        "def tokenized_tensor(data):\n",
        "\n",
        "  output_tokenized = []\n",
        "\n",
        "  for sentence in data:\n",
        "    output = []\n",
        "    tokenized = tokenizer(sentence)\n",
        "    \n",
        "    for word in tokenized:\n",
        "      if word in word2idx:\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "      else:\n",
        "        word2idx[word] = len(word2idx)\n",
        "        id = word2idx[word]\n",
        "        output.append(id)\n",
        "\n",
        "    output = torch.tensor(output)\n",
        "\n",
        "\n",
        "    output_tokenized.append(output)\n",
        "\n",
        "  return output_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K_pDpPLhiUPG"
      },
      "outputs": [],
      "source": [
        "# tokenized_sequences = tokenized_tensor(data)\n",
        "\n",
        "train_tokenized_sequences = tokenized_tensor(train_data)\n",
        "\n",
        "test_tokenized_seuqences = tokenized_tensor(test_data)\n",
        "\n",
        "val_tokenized_seuquences = tokenized_tensor(val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6WOxrifIFKQ",
        "outputId": "ef207cd4-55fc-456f-bc8e-adaadbe1cc96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 162,  435,  180,    1,  306,   59, 4705, 3605])\n"
          ]
        }
      ],
      "source": [
        "print(train_tokenized_sequences[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poFrSB5Opl1-",
        "outputId": "0bad193a-cf73-4f71-e6e9-509bfec95058"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53013"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2idx['<PAD>'] = len(word2idx)\n",
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9AZYccLbVof",
        "outputId": "bf73d6d9-113b-4880-9a85-a27c29d13ae9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53013"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GYstutbgrABv"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (53013,100) into shape (40599,100)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-888a5e5b9ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnew_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnew_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (53013,100) into shape (40599,100)"
          ]
        }
      ],
      "source": [
        "## Create embedding matrix\n",
        "\n",
        "random_init = torch.nn.Parameter(torch.Tensor( (len(word2idx) - vocab_size), vocab_dim))\n",
        "torch.nn.init.kaiming_uniform_(random_init, a=math.sqrt(5))\n",
        "\n",
        "\n",
        "new_matrix = np.zeros( (len(word2idx), vocab_dim) )\n",
        "\n",
        "new_matrix[:vocab_size, :] = embedding_matrix\n",
        "\n",
        "embedding_matrix = new_matrix\n",
        "\n",
        "embedding_matrix[vocab_size:, :] = random_init.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0mL0x6J3KV",
        "outputId": "32d4bf4d-7ec2-4085-fce3-6c7b82f0922a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53013, 100)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53013, 100)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3cp0nnNdrazK"
      },
      "outputs": [],
      "source": [
        "# padded_sequences = pad_sequence(tokenized_sequences, batch_first= True, padding_value=107512)\n",
        "\n",
        "train_padded_sequences = pad_sequence(train_tokenized_sequences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "val_padded_sequences = pad_sequence(val_tokenized_seuquences, batch_first= True, padding_value=word2idx['<PAD>'])\n",
        "\n",
        "test_padded_sequences = pad_sequence(test_tokenized_seuqences, batch_first= True, padding_value=word2idx['<PAD>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trl1D4QFII3e",
        "outputId": "281787e8-4bbd-4b9c-dea0-6f937b0b3f9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  162,   435,   180,     1,   306,    59,  4705,  3605, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "        53013, 53013, 53013, 53013, 53013, 53013])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_padded_sequences[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSE4xlb2O8Ju"
      },
      "source": [
        "### Dataset and Data loader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ISg-6szPOBr1"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
        "    \"\"\"\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.labels = labels\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        sequence = self.sequences[idx]\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        try:\n",
        "            sample[\"label\"] = label\n",
        "            sample[\"token\"] = sequence\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "L1LEy0ogII3g"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_padded_sequences, train_labels)\n",
        "\n",
        "val_dataset = Dataset(val_padded_sequences, val_labels)\n",
        "\n",
        "test_dataset = Dataset(test_padded_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQVUtYvII3g"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC2nFBOTynbR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ENWuqJHeII3h"
      },
      "outputs": [],
      "source": [
        "## Hyper parameter\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "embed_dim = vocab_dim\n",
        "seq_len = 192\n",
        "hidden_size = 512\n",
        "num_layer = 3\n",
        "num_class = 7\n",
        "batch_size = 32\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 30\n",
        "CLIP = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "R2daJrk6PQb7"
      },
      "outputs": [],
      "source": [
        "# # Create datasets\n",
        "# dataset = Dataset(padded_sequences, labels)\n",
        "\n",
        "# split = 0.85\n",
        "# train_size = int(split*len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "LSYO1yrqPSgn"
      },
      "outputs": [],
      "source": [
        "\n",
        "## We call the dataloader class\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "## For testing\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        " )\n",
        "\n",
        "\n",
        "dataloaders = {'Train': train_loader, 'Val': val_loader}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ZYd39BII3i",
        "outputId": "3a10a91c-2116-4ada-e1f6-e3abc17ea147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(296, 31, 65)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoA6yF7iomTV",
        "outputId": "418e1523-d735-4082-f963-16580e8ea844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "695\n"
          ]
        }
      ],
      "source": [
        "max_len = -1\n",
        "for comment in val_dataset:\n",
        "  sentence = comment['token']\n",
        "  max_len = max(max_len,sentence.shape[0])\n",
        "\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0DXO4Q2II3i",
        "outputId": "471b3762-68ba-4ac6-8f4c-2acd20a5b427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'label': tensor(0),\n",
              " 'token': tensor([52566,   364, 52567,   708,     3,   120, 40598, 40598, 40598, 40620,\n",
              "          1513,    89, 30901,     9,  2513,    26, 40620,   109,  5601, 40621,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013, 53013,\n",
              "         53013, 53013, 53013, 53013, 53013, 53013])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXQNerMvjIb"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "wR0tnE2NxphD"
      },
      "outputs": [],
      "source": [
        "class SelfMatchingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,  seq_length, embed_dim, **kwargs):\n",
        "\n",
        "      super(SelfMatchingLayer, self).__init__()\n",
        "\n",
        "      self.seq_length = seq_length\n",
        "      self.embed_dim  = embed_dim\n",
        "\n",
        "      self.P = torch.nn.Parameter(torch.Tensor(self.embed_dim, self.embed_dim))\n",
        "\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.P, a=math.sqrt(5))\n",
        "\n",
        "      \n",
        "    def forward(self, x):  \n",
        "      \n",
        "      # input shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "\n",
        "      #---------------------------------------------#\n",
        "      # calculate weight vector a = {e_i . P.Q . e_j}\n",
        "      #---------------------------------------------#\n",
        "\n",
        "      out = torch.matmul(x,  self.P)   #out shape: [batch, seq_len, embed_dim]\n",
        "\n",
        "      out = torch.matmul(out, torch.transpose(x, 1, 2))   #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = F.gelu(out)         # apply non linear activation\n",
        "\n",
        "      #------------------------------------#\n",
        "      # take row wise mean and apply softmax\n",
        "      #------------------------------------#\n",
        "      out = torch.mean(out, 2)  #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = torch.softmax(out, 0)     #out shape: [batch, seq_len, seq_len]\n",
        "\n",
        "      out = out.unsqueeze(1)          #out shape: [batch, 1, seq_len]\n",
        "\n",
        "      #-------------------------------------------#\n",
        "      # calculate weighted embedding of every word\n",
        "      #-------------------------------------------#\n",
        "      out = torch.matmul(out, x)\n",
        "\n",
        "      out = out.squeeze(1)\n",
        "\n",
        "      return out      #out shape: [batch, seq_len]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkC2PE1q3Fq",
        "outputId": "5188e8ce-3efa-4280-f761-511c46f26e2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53013"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2idx['<PAD>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "LFAeZSyXu9KJ"
      },
      "outputs": [],
      "source": [
        "class SelfNet(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class):\n",
        "        super(SelfNet, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = word2idx['<PAD>'])\n",
        "        self.embedding.load_state_dict({'weight': torch.from_numpy(embedding_matrix)})\n",
        "        self.embedding.weight.requires_grad = True\n",
        "\n",
        "        self.selfnet_layer = SelfMatchingLayer(seq_len, embed_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = num_layer, dropout = 0.3, bidirectional = True, batch_first = True )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2* hidden_size + embed_dim , hidden_size//4)\n",
        "        self.fc2 = nn.Linear(hidden_size//4, num_class)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        embedded = self.embedding(input)  #out shape = [batch, seq_len, embed_dim] \n",
        "\n",
        "        selfmatch_output = self.selfnet_layer(embedded)  #out shape = [batch, seq_len] \n",
        "\n",
        "        lstm_out, _ = self.lstm(embedded)     \n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :]      #out shape = [batch, 2 * hidden_size]      \n",
        "\n",
        "        concat = torch.cat( (selfmatch_output, lstm_out), 1)     #out shape = [batch, 2 * hidden_size + seq_len ]      \n",
        "\n",
        "        linear_out = self.dropout(F.relu(self.fc1(concat)))     #out shape = [batch, hidden_size]      \n",
        "\n",
        "        final_out = self.fc2(linear_out)     #out shape = [batch, 2]      \n",
        "\n",
        "        return final_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Msc1-1zlOtAh"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Padding_idx must be within num_embeddings",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-28cf70afe612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfNet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for batch in train_loader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-995f636b6a5f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/sarcasm_detection/film-master/.env/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, device, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Padding_idx must be within num_embeddings"
          ]
        }
      ],
      "source": [
        "\n",
        "### Test\n",
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)\n",
        "model = model.to(device)\n",
        "\n",
        "# for batch in train_loader:\n",
        "#   x = batch['token'].to(device)\n",
        "#   out = model(x)\n",
        "#   print(out.shape)\n",
        "#   break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-XvE3WHII3l",
        "outputId": "aaf727e6-066f-49bc-d07b-e32dfa27a9a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xjqPfmqx5Hj"
      },
      "source": [
        "### Optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifFhRpc2x4Fv"
      },
      "outputs": [],
      "source": [
        "#optimizer\n",
        "optimizer = Adam(model.parameters(), lr = LEARNING_RATE, eps=1e-8)\n",
        "#Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04ozLaUUx-eo"
      },
      "outputs": [],
      "source": [
        "#to calculate accuracy\n",
        "\n",
        "def get_accuracy(preds, labels):\n",
        "  total_acc = 0.0\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    if labels[i] == preds[i]:\n",
        "      total_acc+=1.0\n",
        "  \n",
        "  return total_acc / len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D33SEPjzILZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP5of6JbII3n",
        "outputId": "58296fc2-81e5-4394-eec6-d979870d53b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "#scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=5, threshold=0.0008, verbose = True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5, verbose = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o0-BUMKII3o"
      },
      "outputs": [],
      "source": [
        "PATH = '/home/ckm/ck_project/codemix/code/selfnet_mihir/models/selfnet_mean+gelu_2_mihir_yt_1.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZkPq1t6yBwx",
        "outputId": "4a678302-dc2f-421d-a886-c7448087ca26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:54<00:00,  3.87batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5169, Precision: 0.5312, Recall : 0.5397, Accuracy: 0.5397, Loss: 0.0111.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.2853, Precision: 0.3340, Recall : 0.3546, Accuracy: 0.3546, Loss: 0.0637.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:54<00:00,  3.87batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5602, Precision: 0.5702, Recall : 0.5777, Accuracy: 0.5777, Loss: 0.0087.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.3723, Precision: 0.3914, Recall : 0.4137, Accuracy: 0.4137, Loss: 0.0663.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:55<00:00,  3.84batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.5909, Precision: 0.5985, Recall : 0.6038, Accuracy: 0.6038, Loss: 0.0102.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.3707, Precision: 0.3889, Recall : 0.4212, Accuracy: 0.4212, Loss: 0.0558.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.78batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.6299, Precision: 0.6359, Recall : 0.6414, Accuracy: 0.6414, Loss: 0.0067.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.3908, Precision: 0.4065, Recall : 0.4409, Accuracy: 0.4409, Loss: 0.0592.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.6708, Precision: 0.6765, Recall : 0.6797, Accuracy: 0.6797, Loss: 0.0101.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4434, Precision: 0.5016, Recall : 0.4939, Accuracy: 0.4939, Loss: 0.0494.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:55<00:00,  3.79batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7072, Precision: 0.7114, Recall : 0.7133, Accuracy: 0.7133, Loss: 0.0068.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4470, Precision: 0.4714, Recall : 0.4952, Accuracy: 0.4952, Loss: 0.0463.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7368, Precision: 0.7405, Recall : 0.7416, Accuracy: 0.7416, Loss: 0.0068.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.4496, Precision: 0.5055, Recall : 0.4973, Accuracy: 0.4973, Loss: 0.0460.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7674, Precision: 0.7691, Recall : 0.7705, Accuracy: 0.7705, Loss: 0.0061.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.5252, Precision: 0.5867, Recall : 0.5469, Accuracy: 0.5469, Loss: 0.0458.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.73batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.7976, Precision: 0.8003, Recall : 0.7998, Accuracy: 0.7998, Loss: 0.0074.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6572, Precision: 0.6762, Recall : 0.6529, Accuracy: 0.6529, Loss: 0.0318.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8187, Precision: 0.8210, Recall : 0.8206, Accuracy: 0.8206, Loss: 0.0044.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6479, Precision: 0.6700, Recall : 0.6447, Accuracy: 0.6447, Loss: 0.0334.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8388, Precision: 0.8409, Recall : 0.8402, Accuracy: 0.8402, Loss: 0.0053.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6835, Precision: 0.6900, Recall : 0.6841, Accuracy: 0.6841, Loss: 0.0323.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.73batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8585, Precision: 0.8595, Recall : 0.8595, Accuracy: 0.8595, Loss: 0.0059.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6614, Precision: 0.6844, Recall : 0.6583, Accuracy: 0.6583, Loss: 0.0355.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8712, Precision: 0.8725, Recall : 0.8722, Accuracy: 0.8722, Loss: 0.0027.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6779, Precision: 0.6882, Recall : 0.6766, Accuracy: 0.6766, Loss: 0.0321.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:55<00:00,  3.79batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8821, Precision: 0.8830, Recall : 0.8831, Accuracy: 0.8831, Loss: 0.0034.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6863, Precision: 0.7070, Recall : 0.6868, Accuracy: 0.6868, Loss: 0.0334.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.8981, Precision: 0.8989, Recall : 0.8989, Accuracy: 0.8989, Loss: 0.0032.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.18batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6880, Precision: 0.7036, Recall : 0.6861, Accuracy: 0.6861, Loss: 0.0733.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.74batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9055, Precision: 0.9057, Recall : 0.9061, Accuracy: 0.9061, Loss: 0.0012.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6993, Precision: 0.7095, Recall : 0.6970, Accuracy: 0.6970, Loss: 0.0489.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9166, Precision: 0.9167, Recall : 0.9170, Accuracy: 0.9170, Loss: 0.0056.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7023, Precision: 0.7180, Recall : 0.7004, Accuracy: 0.7004, Loss: 0.0431.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.79batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9232, Precision: 0.9234, Recall : 0.9235, Accuracy: 0.9235, Loss: 0.0008.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.12batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.6923, Precision: 0.7024, Recall : 0.6902, Accuracy: 0.6902, Loss: 0.0396.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9284, Precision: 0.9287, Recall : 0.9288, Accuracy: 0.9288, Loss: 0.0015.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7060, Precision: 0.7112, Recall : 0.7045, Accuracy: 0.7045, Loss: 0.0601.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9336, Precision: 0.9337, Recall : 0.9338, Accuracy: 0.9338, Loss: 0.0012.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7155, Precision: 0.7235, Recall : 0.7126, Accuracy: 0.7126, Loss: 0.0667.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9370, Precision: 0.9370, Recall : 0.9372, Accuracy: 0.9372, Loss: 0.0020.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7158, Precision: 0.7227, Recall : 0.7133, Accuracy: 0.7133, Loss: 0.0289.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.78batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9419, Precision: 0.9419, Recall : 0.9421, Accuracy: 0.9421, Loss: 0.0031.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7100, Precision: 0.7226, Recall : 0.7072, Accuracy: 0.7072, Loss: 0.0490.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9445, Precision: 0.9446, Recall : 0.9447, Accuracy: 0.9447, Loss: 0.0016.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7187, Precision: 0.7298, Recall : 0.7147, Accuracy: 0.7147, Loss: 0.0324.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9517, Precision: 0.9517, Recall : 0.9518, Accuracy: 0.9518, Loss: 0.0011.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.16batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7032, Precision: 0.7157, Recall : 0.6997, Accuracy: 0.6997, Loss: 0.0516.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.78batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9571, Precision: 0.9572, Recall : 0.9573, Accuracy: 0.9573, Loss: 0.0008.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7113, Precision: 0.7224, Recall : 0.7086, Accuracy: 0.7086, Loss: 0.0395.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9580, Precision: 0.9581, Recall : 0.9581, Accuracy: 0.9581, Loss: 0.0006.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7232, Precision: 0.7333, Recall : 0.7215, Accuracy: 0.7215, Loss: 0.0353.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.74batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9532, Precision: 0.9533, Recall : 0.9533, Accuracy: 0.9533, Loss: 0.0018.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7206, Precision: 0.7334, Recall : 0.7181, Accuracy: 0.7181, Loss: 0.0747.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.76batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9597, Precision: 0.9597, Recall : 0.9598, Accuracy: 0.9598, Loss: 0.0020.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.15batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7276, Precision: 0.7326, Recall : 0.7262, Accuracy: 0.7262, Loss: 0.0766.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:55<00:00,  3.81batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9613, Precision: 0.9613, Recall : 0.9614, Accuracy: 0.9614, Loss: 0.0007.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.13batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7233, Precision: 0.7310, Recall : 0.7208, Accuracy: 0.7208, Loss: 0.0226.\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "--------------------------------------------------\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:56<00:00,  3.75batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "F1: 0.9648, Precision: 0.9649, Recall : 0.9649, Accuracy: 0.9649, Loss: 0.0012.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  8.14batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val:\n",
            "F1: 0.7373, Precision: 0.7415, Recall : 0.7371, Accuracy: 0.7371, Loss: 0.0605.\n",
            "\n",
            "Model Saved!\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ],
      "source": [
        "best_valid_f1 = 0.0000\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "  \n",
        "\n",
        "    print('-'*50)\n",
        "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
        "\n",
        "    for phase in ['Train', 'Val']:\n",
        "\n",
        "        loss = 0.0   #epoch loss\n",
        "        accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        if phase == 'Train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        \n",
        "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
        "\n",
        "          for batch in tepoch:\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            text = batch[\"token\"].to(device)\n",
        "            \n",
        "\n",
        "            output = model(text)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            if phase == 'Train':\n",
        "\n",
        "                #zero gradients\n",
        "                optimizer.zero_grad() \n",
        "\n",
        "                # Backward pass  (calculates the gradients)\n",
        "                loss.backward()   \n",
        "\n",
        "                # gradient clipping\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
        "\n",
        "                optimizer.step()             # Updates the weights    \n",
        "\n",
        "            sleep(0.1)\n",
        "            _, preds = output.data.max(1)\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "            \n",
        "            batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "            \n",
        "            \n",
        "            loss += loss.item()\n",
        "            accuracy+= batch_acc\n",
        "\n",
        "              \n",
        "          epoch_loss = loss / (len(dataloaders[phase]))\n",
        "          epoch_acc = accuracy / (len(dataloaders[phase]))\n",
        "\n",
        "          print(phase + \":\")\n",
        "          \n",
        "          \n",
        "          #print(confusion_matrix(y_true, y_pred))\n",
        "          pre = precision_score(y_true, y_pred, average='weighted')\n",
        "          recall = recall_score(y_true, y_pred, average='weighted')\n",
        "          f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "          \n",
        "\n",
        "          print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))\n",
        "          # save best model\n",
        "          print()\n",
        "          \n",
        "            \n",
        "          if phase == 'Val':\n",
        "                \n",
        "                if f1 > best_valid_f1:\n",
        "                    best_valid_f1 = f1\n",
        "                    \n",
        "                    torch.save(model.state_dict(), PATH)\n",
        "                    print('Model Saved!')\n",
        "                    \n",
        "                scheduler.step()\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yJchRvUz2nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsq5MiaHII3r"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L66ZUsoII3r"
      },
      "outputs": [],
      "source": [
        "model = SelfNet( vocab_size, embed_dim, hidden_size, num_layer, seq_len, num_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EceKQVWTII3r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1DB4Su5II3r"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  7.70batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[154   1   3   2  40  11   0]\n",
            " [  1 145  16   7  20  13   0]\n",
            " [  0  12 191   3   3   3   0]\n",
            " [  3   2   7 147  37  15   2]\n",
            " [ 18  10   2   9 159   7   0]\n",
            " [  5   9  11  15   3 150  33]\n",
            " [  2   2   2   0   0  36 161]]\n",
            "\n",
            "F1: 0.7520, Precision: 0.7520, Recall : 0.7520, Accuracy: 0.7520, Loss: 0.0856.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X99rC-LvII3s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SelfNet(\n",
              "  (embedding): Embedding(44839, 100, padding_idx=44838)\n",
              "  (selfnet_layer): SelfMatchingLayer()\n",
              "  (lstm): LSTM(100, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=1124, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQwRQc_NII3s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:06<00:00,  7.66batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[148   1   3   2  41  14   0]\n",
            " [  1 141  16   8  23  15   0]\n",
            " [  0  12 194   2   3   4   0]\n",
            " [  3   3   6 151  32  19   1]\n",
            " [ 17   9   2   8 162   6   1]\n",
            " [  5   9  11  15   3 145  35]\n",
            " [  1   2   2   0   0  36 160]]\n",
            "\n",
            "F1: 0.7493, Precision: 0.7584, Recall : 0.7480, Accuracy: 0.7480, Loss: 0.0303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQs04_VAII3t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:05<00:00,  7.70batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:\n",
            "\n",
            "[[147   1   3   2  43  14   0]\n",
            " [  0 144  15   7  24  12   1]\n",
            " [  0   9 195   3   3   4   0]\n",
            " [  3   4   5 150  31  20   1]\n",
            " [ 18   9   2  10 158   6   1]\n",
            " [  6  10  11  16   2 148  34]\n",
            " [  2   2   2   0   0  34 160]]\n",
            "\n",
            "F1: 0.7486, Precision: 0.7486, Recall : 0.7486, Accuracy: 0.7486, Loss: 0.0784.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss = 0.0   #epoch loss\n",
        "accuracy = 0.0   #epoch accuracy\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# set the model to evaluation mode            \n",
        "model.eval()\n",
        "        \n",
        "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "  for batch in tepoch:\n",
        "    labels = batch[\"label\"].to(device)\n",
        "    text = batch[\"token\"].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(text)\n",
        "    \n",
        "    \n",
        "    _, preds = output.data.max(1)\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "            \n",
        "    batch_acc = get_accuracy(preds.tolist(), labels.tolist())\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "            \n",
        "            \n",
        "    loss += loss.item()\n",
        "    accuracy+= batch_acc\n",
        "\n",
        "    sleep(0.1)\n",
        "\n",
        "              \n",
        "epoch_loss = loss / (len(val_loader))\n",
        "epoch_acc = accuracy / (len(val_loader))\n",
        "print('')\n",
        "print(\"Inference:\")\n",
        "print(\"\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "pre = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "print(\"\")\n",
        "\n",
        "print(\"F1: {:.4f}, Precision: {:.4f}, Recall : {:.4f}, Accuracy: {:.4f}, Loss: {:.4f}.\".format(f1, pre, recall, epoch_acc, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6Kth3CNII3t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMwq-cvgKn1w"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "SelfNet_mean_+_gelu_Youtube_Comments.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "80812c57c454a5cb47da895f264233db0a5d87621772a622276e795be9a4c20f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('python3.7': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
